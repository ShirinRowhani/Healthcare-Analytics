{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3908bb2d1e246f5877127a9419f6fc4e77e0ddb4"
   },
   "source": [
    "## Predicting discharge statuses for patients presenting to the emergency room"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "299e661498a7a628a96e1162f3ec8019498ddb05"
   },
   "source": [
    "Management of the resources of emergency department facilities based on the number of the patients plays an important role in performance of the hospital by reducing cost and increasing the quality of care.  A large influx of patients at any given time could result in shortage of staff and lack of available rooms.\n",
    "\n",
    "In this context, predicting the outcome of the emergency department visit, whether the patient is admitted to the hospital or sent home,  early on in the patient stay is the objective of this project. \n",
    "\n",
    "The dataset selected for this study is part of the National Hospital Ambulatory Medical Care Survey (NHAMCS) public use data by the US Center for Disease Control and Prevention (CDC). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d36425f3f237136ff5c87ba6ce537bf808edbc5"
   },
   "source": [
    "### Reading data in a fixed-width format (fwf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_uuid": "1a64d485539cc2673304882717256fa30153f27b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   width column_name  variable_type\n",
      "0      2      VMONTH    CATEGORICAL\n",
      "1      1       VDAYR    CATEGORICAL\n",
      "2      4     ARRTIME  NONPREDICTIVE\n",
      "3      4    WAITTIME     CONTINUOUS\n",
      "4      4         LOV  NONPREDICTIVE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "\n",
    "df_helper = pd.read_csv(\n",
    "    '../input/metadata/ED_metadata.csv',\n",
    "    header=0, \n",
    "    dtype={'width': int, 'column_name': str, 'variable_type': str}\n",
    ")\n",
    "print(df_helper.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "1893cc50fe7d47dfbf722dd8859ed4de9a27df90"
   },
   "outputs": [],
   "source": [
    "width = df_helper['width'].tolist()\n",
    "col_names = df_helper['column_name'].tolist()\n",
    "var_types = df_helper['variable_type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "de164d1340f3eca072adad7aa0bedf1203c91bd1"
   },
   "outputs": [],
   "source": [
    "df= pd.read_fwf(\n",
    "    '../input/healthcare/ED2013',\n",
    "    widths=width,\n",
    "    header=None,\n",
    "    dtype='str'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "13bc2999964ba64ded6e3f4eafc74b33152d7c70"
   },
   "outputs": [],
   "source": [
    "df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "75c6c9dcddde37bc656184d54eff7d9c38b57b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      VMONTH VDAYR ARRTIME WAITTIME ...    CSTRATM   CPSUM   PATWT EDWT\n",
      "24772     08     1    1925     0000 ...   40300000  000023  003043  nan\n",
      "24773     08     1    0929     0000 ...   40300000  000023  003043  nan\n",
      "24774     07     1    0116     0000 ...   40300000  000023  003043  nan\n",
      "24775     07     7    1300     0000 ...   40300000  000023  003043  nan\n",
      "24776     07     6    2335     0045 ...   40300000  000023  003043  nan\n",
      "\n",
      "[5 rows x 579 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.tail(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "c90c1c9aa45bcbe2d317744ec873d671f6ee6f9c"
   },
   "outputs": [],
   "source": [
    "# print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "b6678901f8e92b43fa14c9ce8db5c9c15c84facc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24777, 579)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "081a71cd5e5fe59f33c519600667d32574fe794d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22304\n",
       "1     2473\n",
       "Name: ADMITHOS, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ADMITHOS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f7f8e74d34567cae936dc186608061b29bb8c64"
   },
   "source": [
    "## Target Variable\n",
    "\n",
    "In this project, we are trying to predict which patients presenting to the ED will eventually be hospitalized.\n",
    "\n",
    "In this case, hospitalization encompasses:\n",
    "\n",
    "a) Those admitted to an inpatient ward for further evaluation and treatment\n",
    "\n",
    "b) Those transferred to a different hospital (either psychiatric or non-psychiatric) for further treatment\n",
    "\n",
    "c) Those admitted to the observation unit for further evaluation (whether they are eventually admitted or discharged after their observation unit stay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "75ea4467d4a79ee8f8c3d0769c96d3e5bd0694ad"
   },
   "outputs": [],
   "source": [
    "target_cols = ['ADMITHOS','TRANOTH','TRANPSYC','OBSHOS','OBSDIS']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "409172909ba6999cb34a5a14f713d0072a5b966c"
   },
   "source": [
    "def missing(data, target_columns):\n",
    "    for col in target_columns:\n",
    "        data[col]=data[col].replace(['-','7','8','9'],'nan')\n",
    "    return (data, target_columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "830a6469201db460977cdfb2086b7fd51eb9c728"
   },
   "source": [
    "df, target_cols= missing(df,target_cols)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_uuid": "2f2ef72bdb8c49696458b19dceda28b5f7d8ac72"
   },
   "source": [
    "df.loc[:, target_cols] = df.loc[:, target_cols].apply(pd.to_numeric, errors='coerce')\n",
    "df.loc[:, target_cols] = df.loc[:, target_cols].apply(pd.to_numeric,  errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "f458e9fa6ded5c4543c01928686e198f7e4a5e36"
   },
   "outputs": [],
   "source": [
    "df.loc[:, target_cols] = df.loc[:, target_cols].apply(pd.to_numeric)\n",
    "df.loc[:, target_cols] = df.loc[:, target_cols].apply(pd.to_numeric)\n",
    "\n",
    "df['ADMITTEMP'] = df[target_cols].sum(axis=1)\n",
    "\n",
    "df['ADMITFINAL'] = 0\n",
    "df.loc[df['ADMITTEMP'] >= 1, 'ADMITFINAL'] = 1\n",
    "\n",
    "df.drop(target_cols, axis=1, inplace=True)\n",
    "df.drop('ADMITTEMP', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3e73d5db7b356111095608911cdbd3a365412bc"
   },
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "1d4bf0a9b3744725cd0cef7e52dbc02fa32c1566"
   },
   "outputs": [],
   "source": [
    "def split_target(data, target_name):\n",
    "    target = data[[target_name]]\n",
    "    data.drop(target_name, axis=1, inplace=True)\n",
    "    return (data, target)\n",
    "\n",
    "X, y = split_target(df, 'ADMITFINAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "9a8393233a992a35b1de2f1320471ab954ffac6c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "a8517d49d9d5ec1c052bdc5a6ad2f0525db690cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMITFINAL\n",
      "0    16028\n",
      "1     2554\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.groupby('ADMITFINAL').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85509ecc43b5b3dc8435883cb7e1c484faaf276a"
   },
   "source": [
    "## Preprocessing the Predictor Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "076ba4a9458e53e5781ccf86af0a5b9b2a3e62fb"
   },
   "source": [
    "### Visit information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa55ba1b0774385ef5648b6affb1c7d5ecaaec14"
   },
   "source": [
    "#### Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_uuid": "98fc8534e609597e08cdf8647700cedd3ecd6425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMONTH\n",
      "01    1780\n",
      "02    1369\n",
      "03    1433\n",
      "04    1705\n",
      "05    2034\n",
      "06    1716\n",
      "07    1768\n",
      "08    1038\n",
      "09    1225\n",
      "10    1273\n",
      "11    1669\n",
      "12    1572\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.groupby('VMONTH').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "2dc8d723bb04bb980da0c3eeb8344b8d75a15eb7"
   },
   "outputs": [],
   "source": [
    "def is_winter(vmonth):\n",
    "    if vmonth in ['12','01','02','03']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X_train.loc[:,'WINTER'] = df.loc[:,'VMONTH'].apply(is_winter)\n",
    "X_test.loc[:,'WINTER'] = df.loc[:,'VMONTH'].apply(is_winter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e30028ccd8d4ea9ef6aa9052a0d1df0760ec9f5a"
   },
   "source": [
    "#### Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "45b4cc95e8bb614c4e3026a5ff9eb6c20525b632"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VDAYR\n",
       "1    2576\n",
       "2    2959\n",
       "3    2775\n",
       "4    2655\n",
       "5    2529\n",
       "6    2545\n",
       "7    2543\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.groupby('VDAYR').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b821795fafa58c4244b1e1d8cef935124dec9e34"
   },
   "source": [
    "#### Arrival Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "be53538a22e0304219feeb3d7052cccde377d0c1"
   },
   "outputs": [],
   "source": [
    "def is_night(arrtime):\n",
    "    arrtime_int = int(arrtime)\n",
    "    if ((arrtime_int >= 0) & (arrtime_int < 800)):\n",
    "        return 1\n",
    "    elif ((arrtime_int >= 2000) & (arrtime_int < 2400)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X_train.loc[:,'NIGHT'] = df.loc[:,'ARRTIME'].apply(is_night)\n",
    "X_test.loc[:,'NIGHT'] = df.loc[:,'ARRTIME'].apply(is_night)\n",
    "\n",
    "X_train.drop('ARRTIME', axis=1, inplace=True)\n",
    "X_test.drop('ARRTIME', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79a1617458e8dba040930ea885af78abcf2da47b"
   },
   "source": [
    "#### Wait Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "e9fd5f635260f47bb470dcec237b876086af46ad"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'WAITTIME'] = X_train.loc[:,'WAITTIME'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'WAITTIME'] = X_test.loc[:,'WAITTIME'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e3f6fe2860a0d0dde7a6122f9189255fd30874a"
   },
   "source": [
    "### Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_uuid": "a2454961999bd2ae1e50a675d0861910abe346fe"
   },
   "outputs": [],
   "source": [
    "# Mean imputation In the documentation\n",
    "# The WAITTIME variable may take values of -9 and -7 when blank and not applicable, respectively. \n",
    "\n",
    "def mean_impute_values(data,col):  \n",
    "    temp_mean = data.loc[(data[col] != -7) & (data[col] != -9), col].mean()\n",
    "    data.loc[(data[col] == -7) | (data[col] == -9), col] = temp_mean            \n",
    "    return data\n",
    "\n",
    "X_train = mean_impute_values(X_train,'WAITTIME')\n",
    "X_test = mean_impute_values(X_test,'WAITTIME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2afa1e8ef5075d1f5717af8385511aad3179816e"
   },
   "source": [
    "#### Dropping other visit variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "b372a7e4fa6ffcdb5d16a4e42710da70528b430b"
   },
   "outputs": [],
   "source": [
    "X_train.drop('LOV', axis=1, inplace=True)\n",
    "X_test.drop('LOV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f26805c0c94eb45d716a884d27b7117075662ae"
   },
   "source": [
    "## Demographic Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1df08d257ad6e15e5268a9643c5e3b5de22f761e"
   },
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "30846a1165f2f4f3170e29f93cb76cc0065a2166"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'AGE'] = X_train.loc[:,'AGE'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'AGE'] = X_test.loc[:,'AGE'].apply(pd.to_numeric)\n",
    "\n",
    "X_train.drop('AGEDAYS', axis=1, inplace=True)\n",
    "X_test.drop('AGEDAYS', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d1023ad970ceb182c116bd1b1564ab7798cfca0"
   },
   "source": [
    "#### Sex\n",
    "\n",
    "We keep the sex column as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7fdeabc32e96cf4885e803e296f122eec3b4ee8d"
   },
   "source": [
    "#### Ethnicity and race\n",
    "We leave the unimputed ethnicity and race variables (ETHUN and RACEUN) as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "b804171169a44d85477cf2f83c6a14f8b9603caf"
   },
   "outputs": [],
   "source": [
    "X_train.drop(['ETHIM','RACER','RACERETH'], axis=1, inplace=True)\n",
    "X_test.drop(['ETHIM','RACER','RACERETH'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1894b4c5f5f49312044f68cbe28029302b6b272"
   },
   "source": [
    "## Triage Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2805ca669e59d85cbe4443022407571d85190384"
   },
   "source": [
    "The IMMEDR variable represents the triage scores that range from 1 (critical) to 5 (non-urgent). \n",
    "\n",
    "ARREMS that shows whether or not the patient arrived via EMS and SEEN72 that indecate whether or not the patient has been seen and discharged within the last 72 hours (SEEN72) will also get included in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "740b5ea408d994bf1f855342e9cf41e0b940a4e2"
   },
   "source": [
    "## Financial Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "332c5a5c7b9682cd9aa3bc2fef53e219d4b8e480"
   },
   "source": [
    "We include all of the financial variables in our model except for the PAYTYPER variable, which is a nonbinary expansion of the other payment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "40ad758bacaf1292ba8dce86285d3ededab50e2f"
   },
   "outputs": [],
   "source": [
    "X_train.drop('PAYTYPER', axis=1, inplace=True)\n",
    "X_test.drop('PAYTYPER', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0b722584cb74d277755b8ca6f97185fe25dc83f"
   },
   "source": [
    "## Vital Signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "06352e494b5961b4d2afcf64c7d7de31e7223c87"
   },
   "source": [
    "#### Temperature\n",
    "\n",
    "In the dataset all temoratures are multiplied by 10 so we need to devide them by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "_uuid": "2e185294147754b8739aede96701bf4776a93fe2"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'TEMPF'] = X_train.loc[:,'TEMPF'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'TEMPF'] = X_test.loc[:,'TEMPF'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'TEMPF')\n",
    "X_test = mean_impute_values(X_test,'TEMPF')\n",
    "\n",
    "X_train.loc[:,'TEMPF'] = X_train.loc[:,'TEMPF'].apply(lambda x: float(x)/10)\n",
    "X_test.loc[:,'TEMPF'] = X_test.loc[:,'TEMPF'].apply(lambda x: float(x)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_uuid": "ae95e0826b0565e5c1f3a1b6bbad8283edf6036b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4232     98.7\n",
       "20594    98.1\n",
       "10153    98.7\n",
       "15805    98.4\n",
       "18066    98.0\n",
       "6497     98.4\n",
       "5395     98.4\n",
       "13974    98.3\n",
       "9200     97.5\n",
       "12244    99.5\n",
       "Name: TEMPF, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['TEMPF'].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a47ab2899bde0f678219fdf45857b09ac680cdbd"
   },
   "source": [
    "#### Pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_uuid": "2bfaaf85f7f64ec369842e6b3039bcdf91e6a5d8"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'PULSE'] = X_train.loc[:,'PULSE'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'PULSE'] = X_test.loc[:,'PULSE'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_uuid": "f27a0d95378e0b4d842c1c26b8a347270c671068"
   },
   "outputs": [],
   "source": [
    "def mean_impute_vitals(data,col): \n",
    "    temp_mean = data.loc[(data[col] != 998) & (data[col] != -9), col].mean()\n",
    "    data.loc[(data[col] == 998) | (data[col] == -9), col] = temp_mean \n",
    "    return data\n",
    "\n",
    "X_train = mean_impute_vitals(X_train,'PULSE')\n",
    "X_test = mean_impute_vitals(X_test,'PULSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e51744e4ce0eaaefa091fd4764cb5dbe70c5071"
   },
   "source": [
    "#### Respiratory Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "_uuid": "956d8e5250e051ecc9b186956b5ee262f0724410"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'RESPR'] = X_train.loc[:,'RESPR'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'RESPR'] = X_test.loc[:,'RESPR'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'RESPR')\n",
    "X_test = mean_impute_values(X_test,'RESPR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b47794c42b8043814a6e388bfbaba0f9370c8c6d"
   },
   "source": [
    "#### Blood pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "_uuid": "574e8fe38c2de50dd4c3c44a77065ce56c129c1b"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'BPSYS'] = X_train.loc[:,'BPSYS'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'BPSYS'] = X_test.loc[:,'BPSYS'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'BPSYS')\n",
    "X_test = mean_impute_values(X_test,'BPSYS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "_uuid": "7d738c7e73562b6dca470427392ee87deec69f08"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'BPDIAS'] = X_train.loc[:,'BPDIAS'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'BPDIAS'] = X_test.loc[:,'BPDIAS'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_uuid": "50de3520a3ab0e3fa459831576103d40eb6584a6"
   },
   "outputs": [],
   "source": [
    "def mean_impute_bp_diast(data,col): \n",
    "    temp_mean = data.loc[(data[col] != 998) & (data[col] != -9), col].mean()\n",
    "    data.loc[data[col] == 998, col] = 40\n",
    "    data.loc[data[col] == -9, col] = temp_mean \n",
    "    return data\n",
    "\n",
    "X_train = mean_impute_values(X_train,'BPDIAS')\n",
    "X_test = mean_impute_values(X_test,'BPDIAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9457200d765fac08b555b45f7ca60d87a8546100"
   },
   "source": [
    "#### Oxygen saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_uuid": "2e3b3faeb81864e48171a140399a6189e4bc6086"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'POPCT'] = X_train.loc[:,'POPCT'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'POPCT'] = X_test.loc[:,'POPCT'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'POPCT')\n",
    "X_test = mean_impute_values(X_test,'POPCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "_uuid": "49faa1122aab0c4e15aacdab724d118831134689"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPF</th>\n",
       "      <th>PULSE</th>\n",
       "      <th>RESPR</th>\n",
       "      <th>BPSYS</th>\n",
       "      <th>BPDIAS</th>\n",
       "      <th>POPCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>98.7</td>\n",
       "      <td>73.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20594</th>\n",
       "      <td>98.1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10153</th>\n",
       "      <td>98.7</td>\n",
       "      <td>98.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>160.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15805</th>\n",
       "      <td>98.4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>19.568148</td>\n",
       "      <td>111.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18066</th>\n",
       "      <td>98.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>98.4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>98.4</td>\n",
       "      <td>152.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>125.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13974</th>\n",
       "      <td>98.3</td>\n",
       "      <td>115.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>133.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9200</th>\n",
       "      <td>97.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12244</th>\n",
       "      <td>99.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>158.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TEMPF  PULSE      RESPR  BPSYS  BPDIAS  POPCT\n",
       "4232    98.7   73.0  20.000000  118.0    61.0  100.0\n",
       "20594   98.1   86.0  20.000000  148.0    85.0   98.0\n",
       "10153   98.7   98.0  28.000000  160.0   106.0  100.0\n",
       "15805   98.4   75.0  19.568148  111.0    58.0  100.0\n",
       "18066   98.0  109.0  18.000000  199.0   111.0   94.0\n",
       "6497    98.4   88.0  16.000000  169.0    85.0   95.0\n",
       "5395    98.4  152.0  40.000000  125.0    77.0   95.0\n",
       "13974   98.3  115.0  22.000000  133.0    73.0   96.0\n",
       "9200    97.5   81.0  18.000000  140.0    68.0   96.0\n",
       "12244   99.5  110.0  20.000000  158.0   107.0  100.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['TEMPF','PULSE','RESPR','BPSYS','BPDIAS','POPCT']].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "291435580e46b82cfe646cb7811bb1c3f7b50c85"
   },
   "source": [
    "#### Pain level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "_uuid": "e6c94534630ab1a5942869ac891a9dae73d00a79"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'PAINSCALE'] = X_train.loc[:,'PAINSCALE'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'PAINSCALE'] = X_test.loc[:,'PAINSCALE'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "_uuid": "242720cd1a203fc14108954f93caacbb8de71fbd"
   },
   "outputs": [],
   "source": [
    "def mean_impute_pain(data,col): \n",
    "    temp_mean = data.loc[(data[col] != -8) & (data[col] != -9), col].mean()\n",
    "    data.loc[(data[col] == -8) | (data[col] == -9), col] = temp_mean \n",
    "    return data\n",
    "\n",
    "X_train = mean_impute_pain(X_train,'PAINSCALE')\n",
    "X_test = mean_impute_pain(X_test,'PAINSCALE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d051bf29d03d211d90cda64d40507140bce85068"
   },
   "source": [
    "### Reason-for-visit codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "_uuid": "2bade0c202928960905ac059d7de91d4e8cb3086"
   },
   "outputs": [],
   "source": [
    "rfv_codes_path = '../input/rfv-codes/RFV_CODES.csv'\n",
    "\n",
    "rfv_codes = pd.read_csv(rfv_codes_path,header=0,dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "_uuid": "99fc2e635dbe79175cf950e4d8b15b760c4f6f88"
   },
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "def add_rfv_column(data,code,desc,rfv_columns):\n",
    "    column_name = 'rfv_' + sub(\" \", \"_\", desc)\n",
    "    data[column_name] = (data[rfv_columns] == rfv_code).any(axis=1).astype('int')\n",
    "    return data\n",
    "\n",
    "rfv_columns = ['RFV1','RFV2','RFV3']\n",
    "for (rfv_code,rfv_desc) in zip(\n",
    "    rfv_codes['Code'].tolist(),rfv_codes['Description'].tolist()\n",
    "):\n",
    "    X_train = add_rfv_column(\n",
    "        X_train,\n",
    "        rfv_code,\n",
    "        rfv_desc,\n",
    "        rfv_columns\n",
    "    )\n",
    "    X_test = add_rfv_column(\n",
    "        X_test,\n",
    "        rfv_code,\n",
    "        rfv_desc,\n",
    "        rfv_columns \n",
    "    )\n",
    "    \n",
    "# Remove original RFV columns\n",
    "X_train.drop(rfv_columns, axis=1, inplace=True)\n",
    "X_test.drop(rfv_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "_uuid": "81a45abf7a2a51000c071dbb3c485b5b7046bba8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VMONTH</th>\n",
       "      <th>VDAYR</th>\n",
       "      <th>WAITTIME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGER</th>\n",
       "      <th>RESIDNCE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ETHUN</th>\n",
       "      <th>RACEUN</th>\n",
       "      <th>ARREMS</th>\n",
       "      <th>NOPAY</th>\n",
       "      <th>PAYPRIV</th>\n",
       "      <th>PAYMCARE</th>\n",
       "      <th>PAYMCAID</th>\n",
       "      <th>PAYWKCMP</th>\n",
       "      <th>PAYSELF</th>\n",
       "      <th>PAYNOCHG</th>\n",
       "      <th>PAYOTH</th>\n",
       "      <th>PAYDK</th>\n",
       "      <th>TEMPF</th>\n",
       "      <th>PULSE</th>\n",
       "      <th>RESPR</th>\n",
       "      <th>BPSYS</th>\n",
       "      <th>BPDIAS</th>\n",
       "      <th>POPCT</th>\n",
       "      <th>ONO2</th>\n",
       "      <th>IMMEDR</th>\n",
       "      <th>PAINSCALE</th>\n",
       "      <th>SEEN72</th>\n",
       "      <th>EPISODE</th>\n",
       "      <th>INJURY</th>\n",
       "      <th>INJR1</th>\n",
       "      <th>INJR2</th>\n",
       "      <th>INJPOISAD</th>\n",
       "      <th>INJPOISADR1</th>\n",
       "      <th>INJPOISADR2</th>\n",
       "      <th>INTENT</th>\n",
       "      <th>INJDETR</th>\n",
       "      <th>INJDETR1</th>\n",
       "      <th>INJDETR2</th>\n",
       "      <th>...</th>\n",
       "      <th>rfv_Food_poisoning</th>\n",
       "      <th>rfv_Ingestion_inhalation_or_exposure_to_potentially_poisonous_products</th>\n",
       "      <th>rfv_Adverse_effect_of_medication</th>\n",
       "      <th>rfv_Adverse_effect_of_drug_abuse</th>\n",
       "      <th>rfv_Adverse_effect_of_alcohol</th>\n",
       "      <th>rfv_Alcohol_poisoning</th>\n",
       "      <th>rfv_Adverse_effects_of_environment</th>\n",
       "      <th>rfv_Adverse_effects_of_secondhand_smoke</th>\n",
       "      <th>rfv_Adverse_effects_of_terrorism_and_bioterrorism</th>\n",
       "      <th>rfv_Adverse_effects_other_and_unspecified</th>\n",
       "      <th>rfv_Complications_of_surgical_or_medical_procedures_and_treatments</th>\n",
       "      <th>rfv_For_other_findings_of_blood_tests</th>\n",
       "      <th>rfv_For_results_of_urine_tests</th>\n",
       "      <th>rfv_For_cytology_findings</th>\n",
       "      <th>rfv_For_radiological_findings</th>\n",
       "      <th>rfv_For_results_of_blood_glucose_tests</th>\n",
       "      <th>rfv_For_results_of_EKG_Holter_monitor_review_abnormal</th>\n",
       "      <th>rfv_For_results_of_skin_tests</th>\n",
       "      <th>rfv_For_results_of_cholesterol_and_triglyceride_tests</th>\n",
       "      <th>rfv_For_other_and_unspecified_test_results</th>\n",
       "      <th>rfv_For_results_of_test_for_human_immunodeficiency</th>\n",
       "      <th>rfv_Physical_examination_required_for_school_or_employment</th>\n",
       "      <th>rfv_Other_reason_for_visit_required_by_party_other_than_the_patient_or_the_health_care_provider</th>\n",
       "      <th>rfv_Physical_examination_required_for_employment</th>\n",
       "      <th>rfv_Executive_physical_examination</th>\n",
       "      <th>rfv_Physical_examination_required_for_school</th>\n",
       "      <th>rfv_Problems_complaints_NEC</th>\n",
       "      <th>rfv_Patient_unable_to_speak_English</th>\n",
       "      <th>rfv_Patient_or_patient's_spokesperson_refused_care</th>\n",
       "      <th>rfv_Physical_examination_for_extracurricular_activities</th>\n",
       "      <th>rfv_Entry_of_none_or_no_complaint</th>\n",
       "      <th>rfv_Insufficient_information</th>\n",
       "      <th>rfv_Driver's_license_examination_DOT_</th>\n",
       "      <th>rfv_Illegible_entry</th>\n",
       "      <th>rfv_Insurance_examination_</th>\n",
       "      <th>rfv_Disability_examination_</th>\n",
       "      <th>rfv_Workerâ€™s_comp_exam</th>\n",
       "      <th>rfv_Premarital_examination</th>\n",
       "      <th>rfv_Premarital_blood_test</th>\n",
       "      <th>rfv_Direct_admission_to_hospital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>06</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>73.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>4.776526</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>-9</td>\n",
       "      <td>05</td>\n",
       "      <td>05</td>\n",
       "      <td>05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20594</th>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>-9</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10153</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>98.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>160.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>02</td>\n",
       "      <td>04</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15805</th>\n",
       "      <td>04</td>\n",
       "      <td>3</td>\n",
       "      <td>139.0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>19.568148</td>\n",
       "      <td>111.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>-9</td>\n",
       "      <td>05</td>\n",
       "      <td>05</td>\n",
       "      <td>05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18066</th>\n",
       "      <td>09</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>02</td>\n",
       "      <td>-8</td>\n",
       "      <td>4.776526</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>-9</td>\n",
       "      <td>05</td>\n",
       "      <td>05</td>\n",
       "      <td>05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VMONTH               ...                rfv_Direct_admission_to_hospital\n",
       "4232      06               ...                                               0\n",
       "20594     01               ...                                               0\n",
       "10153     10               ...                                               0\n",
       "15805     04               ...                                               0\n",
       "18066     09               ...                                               0\n",
       "\n",
       "[5 rows x 1264 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "865df7ca98a6024b1bb6b785c44268be63d8b126"
   },
   "source": [
    "### Injury codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4c008289ddf45f644e400b38d1e581d36bd882b"
   },
   "source": [
    "Injury codes only apply if the patient has undergone either physical injury, poisoning, or adverse effects of medical treatment (including suicide attempts). Because the exact reason for injury may not be known until a full workup has been performed, and that workup usually occurs after a decision to admit has already been made. Therefore, we will remove the injury code variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "_uuid": "cf5851a77e241ab625e4f34f195e48c586f04c6d"
   },
   "outputs": [],
   "source": [
    "inj_cols = [\n",
    "    'INJURY','INJR1','INJR2','INJPOISAD','INJPOISADR1',\n",
    "    'INJPOISADR2','INTENT','INJDETR','INJDETR1','INJDETR2',\n",
    "    'CAUSE1','CAUSE2','CAUSE3','CAUSE1R','CAUSE2R','CAUSE3R'\n",
    "]\n",
    "\n",
    "X_train.drop(inj_cols, axis=1, inplace=True)\n",
    "X_test.drop(inj_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89e8beff2d203e5d5cbd4e213b6b9854f995028f"
   },
   "source": [
    "### Diagnostic codes\n",
    "For the same reason as the injury codes, these variables will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "_uuid": "74f49936c1dd445a53dca31681b120986343dc5e"
   },
   "outputs": [],
   "source": [
    "diag_cols= [\n",
    "    'DIAG1','DIAG2','DIAG3',\n",
    "    'PRDIAG1','PRDIAG2','PRDIAG3',\n",
    "    'DIAG1R','DIAG2R','DIAG3R'\n",
    "]\n",
    "\n",
    "X_train.drop(diag_cols, axis=1, inplace=True)\n",
    "X_test.drop(diag_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96f9a4c8863592337d3be696047d1b53da3d32d3"
   },
   "source": [
    "### Medical history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "_uuid": "704eb2c2525a595f0c3583c6ad7f7f54ef055b68"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'TOTCHRON'] = X_train.loc[:,'TOTCHRON'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'TOTCHRON'] = X_test.loc[:,'TOTCHRON'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'TOTCHRON')\n",
    "X_test = mean_impute_values(X_test,'TOTCHRON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3ac9f4f336b69993e11edf16c90cdc450198d05"
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "_uuid": "199ab7c79ed83dd9b1bc98ba67ad2a807ef1e17c"
   },
   "outputs": [],
   "source": [
    "testing_cols = [\n",
    "    'ABG','BAC','BLOODCX','BNP','BUNCREAT',\n",
    "    'CARDENZ','CBC','DDIMER','ELECTROL','GLUCOSE',\n",
    "    'LACTATE','LFT','PTTINR','OTHERBLD','CARDMON',\n",
    "    'EKG','HIVTEST','FLUTEST','PREGTEST','TOXSCREN',\n",
    "    'URINE','WOUNDCX','URINECX','OTHRTEST','ANYIMAGE',\n",
    "    'XRAY','IVCONTRAST','CATSCAN','CTAB','CTCHEST',\n",
    "    'CTHEAD','CTOTHER','CTUNK','MRI','ULTRASND',\n",
    "    'OTHIMAGE','TOTDIAG','DIAGSCRN'\n",
    "]\n",
    "\n",
    "X_train.drop(testing_cols, axis=1, inplace=True)\n",
    "X_test.drop(testing_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "12fa2f064c175af442c3f6c03461977bd2900549"
   },
   "source": [
    "### Procedures\n",
    "We omit procedures because, similar to the tests, they often occur post-prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "_uuid": "2233255b79c17a4ffddabcd23f1db0a19e5e5238"
   },
   "outputs": [],
   "source": [
    "proc_cols = [\n",
    "    'PROC','BPAP','BLADCATH','CASTSPLINT','CENTLINE',\n",
    "    'CPR','ENDOINT','INCDRAIN','IVFLUIDS','LUMBAR',\n",
    "    'NEBUTHER','PELVIC','SKINADH','SUTURE','OTHPROC',\n",
    "    'TOTPROC'\n",
    "]\n",
    "\n",
    "X_train.drop(proc_cols, axis=1, inplace=True)\n",
    "X_test.drop(proc_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68530a811af252a0d77d1062177755d509d6c6c8"
   },
   "source": [
    "### Medication codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "_uuid": "4488d3d9d49ebc2c9cc632f46d0c718815776166"
   },
   "outputs": [],
   "source": [
    "med_cols = [\n",
    "    'MED1','MED2','MED3','MED4','MED5',\n",
    "    'MED6','MED7','MED8','MED9','MED10',\n",
    "    'MED11','MED12','GPMED1','GPMED2','GPMED3',\n",
    "    'GPMED4','GPMED5','GPMED6','GPMED7','GPMED8',\n",
    "    'GPMED9','GPMED10','GPMED11','GPMED12','NUMGIV',\n",
    "    'NUMDIS','NUMMED',\n",
    "]\n",
    "\n",
    "X_train.drop(med_cols, axis=1, inplace=True)\n",
    "X_test.drop(med_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15473faa7f88085a934cb4fdd0622ab5865e2727"
   },
   "source": [
    "### Provider information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "_uuid": "e39da49652879d3576cb7b444e0a15a8eb714bdc"
   },
   "outputs": [],
   "source": [
    "prov_cols = [\n",
    "    'NOPROVID','ATTPHYS','RESINT','CONSULT','RNLPN',\n",
    "    'NURSEPR','PHYSASST','EMT','MHPROV','OTHPROV'\n",
    "]\n",
    "\n",
    "X_train.drop(prov_cols, axis=1, inplace=True)\n",
    "X_test.drop(prov_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23c4944737f59c4567042991d0e4df7ecad2cc1b"
   },
   "source": [
    "### Disposition information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "_uuid": "07e69ec8d6589cf6a573b5a56556502f13da60da"
   },
   "outputs": [],
   "source": [
    "disp_cols = [\n",
    "    'NODISP','NOFU','RETRNED','RETREFFU','LEFTBTRI',\n",
    "    'LEFTAMA','DOA','DIEDED','TRANNH','OTHDISP',\n",
    "    'ADMIT','ADMTPHYS','BOARDED','LOS','HDDIAG1',\n",
    "    'HDDIAG2','HDDIAG3','HDDIAG1R','HDDIAG2R','HDDIAG3R',\n",
    "    'HDSTAT','ADISP','OBSSTAY','STAY24'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "_uuid": "dff2a9804ee48b8a18c8fd8fd1c16cb4839e87a3"
   },
   "outputs": [],
   "source": [
    "X_train.drop(disp_cols, axis=1, inplace=True)\n",
    "X_test.drop(disp_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a2d2515da97ea10b85ae5f4b5a3745ccfb99f34"
   },
   "source": [
    "### Pre-Imputed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "_uuid": "3143903fab2248fd5ae79fae7cd8538e9eff0d0a"
   },
   "outputs": [],
   "source": [
    "imp_cols = [\n",
    "    'AGEFL','BDATEFL','SEXFL','ETHNICFL','RACERFL'\n",
    "]\n",
    "\n",
    "X_train.drop(imp_cols, axis=1, inplace=True)\n",
    "X_test.drop(imp_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccd0180ed16932207b12bbc909fd1151fc12c885"
   },
   "source": [
    "### Identifying variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "_uuid": "30963e91209a6ee5e9c0db95285a4021d1ef9df0"
   },
   "outputs": [],
   "source": [
    "id_cols = [\n",
    "    'HOSPCODE','PATCODE'\n",
    "]\n",
    "\n",
    "X_train.drop(id_cols, axis=1, inplace=True)\n",
    "X_test.drop(id_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e7df181220b1be822c4e721e390aa28e24fdc3f4"
   },
   "source": [
    "### Electronic medical record status columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4921b76b3fc004400aaa4b01114f6939773ce6ed"
   },
   "source": [
    "We omit these columns since they are valued on a per-hospital basis rather than a per-encounter basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "_uuid": "32014be22e6949ebda0f26c6a1d5d3630bdfaf18"
   },
   "outputs": [],
   "source": [
    "emr_cols = [\n",
    "    'EBILLANYE','EMRED','HHSMUE','EHRINSE','EDEMOGE',\n",
    "    'EDEMOGER','EPROLSTE','EPROLSTER','EVITALE','EVITALER',\n",
    "    'ESMOKEE','ESMOKEER','EPNOTESE','EPNOTESER','EMEDALGE',\n",
    "    'EMEDALGER','ECPOEE','ECPOEER','ESCRIPE','ESCRIPER',\n",
    "    'EWARNE','EWARNER','EREMINDE','EREMINDER','ECTOEE',\n",
    "    'ECTOEER','EORDERE','EORDERER','ERESULTE','ERESULTER',\n",
    "    'EGRAPHE','EGRAPHER','EIMGRESE','EIMGRESER','EPTEDUE',\n",
    "    'EPTEDUER','ECQME','ECQMER','EGENLISTE','EGENLISTER',\n",
    "    'EIMMREGE','EIMMREGER','ESUME','ESUMER','EMSGE',\n",
    "    'EMSGER','EHLTHINFOE','EHLTHINFOER','EPTRECE','EPTRECER',\n",
    "    'EMEDIDE','EMEDIDER','ESHAREE','ESHAREEHRE','ESHAREWEBE',\n",
    "    'ESHAREOTHE','ESHAREUNKE','ESHAREREFE','LABRESE1','LABRESE2',\n",
    "    'LABRESE3','LABRESE4','LABRESUNKE','LABRESREFE','IMAGREPE1',\n",
    "    'IMAGREPE2','IMAGREPE3','IMAGREPE4','IMAGREPUNKE','IMAGREPREFE',\n",
    "    'PTPROBE1','PTPROBE2','PTPROBE3','PTPROBE4','PTPROBUNKE',\n",
    "    'PTPROBREFE','MEDLISTE1','MEDLISTE2','MEDLISTE3','MEDLISTE4',\n",
    "    'MEDLISTUNKE','MEDLISTREFE','ALGLISTE1','ALGLISTE2','ALGLISTE3',\n",
    "    'ALGLISTE4','ALGLISTUNKE','ALGLISTREFE','EDPRIM','EDINFO',\n",
    "    'MUINC','MUYEAR'\n",
    "]\n",
    "\n",
    "X_train.drop(emr_cols, axis=1, inplace=True)\n",
    "X_test.drop(emr_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "446a17da02781df810bc5bc28803012f27cd4edd"
   },
   "source": [
    "### Detailed medication information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "_uuid": "e2c8a6492ea41de04668ad95e8ab108191396bb5"
   },
   "outputs": [],
   "source": [
    "drug_id_cols = [\n",
    "    'DRUGID1','DRUGID2','DRUGID3','DRUGID4','DRUGID5',\n",
    "    'DRUGID6','DRUGID7','DRUGID8','DRUGID9','DRUGID10',\n",
    "    'DRUGID11','DRUGID12'\n",
    "]\n",
    "\n",
    "drug_lev1_cols = [\n",
    "    'RX1V1C1','RX1V1C2','RX1V1C3','RX1V1C4',\n",
    "    'RX2V1C1','RX2V1C2','RX2V1C3','RX2V1C4',\n",
    "    'RX3V1C1','RX3V1C2','RX3V1C3','RX3V1C4',\n",
    "    'RX4V1C1','RX4V1C2','RX4V1C3','RX4V1C4',\n",
    "    'RX5V1C1','RX5V1C2','RX5V1C3','RX5V1C4',\n",
    "    'RX6V1C1','RX6V1C2','RX6V1C3','RX6V1C4',\n",
    "    'RX7V1C1','RX7V1C2','RX7V1C3','RX7V1C4',\n",
    "    'RX8V1C1','RX8V1C2','RX8V1C3','RX8V1C4',\n",
    "    'RX9V1C1','RX9V1C2','RX9V1C3','RX9V1C4',\n",
    "    'RX10V1C1','RX10V1C2','RX10V1C3','RX10V1C4',\n",
    "    'RX11V1C1','RX11V1C2','RX11V1C3','RX11V1C4',\n",
    "    'RX12V1C1','RX12V1C2','RX12V1C3','RX12V1C4'\n",
    "]\n",
    "\n",
    "drug_lev2_cols = [\n",
    "    'RX1V2C1','RX1V2C2','RX1V2C3','RX1V2C4',\n",
    "    'RX2V2C1','RX2V2C2','RX2V2C3','RX2V2C4',\n",
    "    'RX3V2C1','RX3V2C2','RX3V2C3','RX3V2C4',\n",
    "    'RX4V2C1','RX4V2C2','RX4V2C3','RX4V2C4',\n",
    "    'RX5V2C1','RX5V2C2','RX5V2C3','RX5V2C4',\n",
    "    'RX6V2C1','RX6V2C2','RX6V2C3','RX6V2C4',\n",
    "    'RX7V2C1','RX7V2C2','RX7V2C3','RX7V2C4',\n",
    "    'RX8V2C1','RX8V2C2','RX8V2C3','RX8V2C4',\n",
    "    'RX9V2C1','RX9V2C2','RX9V2C3','RX9V2C4',\n",
    "    'RX10V2C1','RX10V2C2','RX10V2C3','RX10V2C4',\n",
    "    'RX11V2C1','RX11V2C2','RX11V2C3','RX11V2C4',\n",
    "    'RX12V2C1','RX12V2C2','RX12V2C3','RX12V2C4'\n",
    "]\n",
    "drug_lev3_cols = [\n",
    "    'RX1V3C1','RX1V3C2','RX1V3C3','RX1V3C4',\n",
    "    'RX2V3C1','RX2V3C2','RX2V3C3','RX2V3C4',\n",
    "    'RX3V3C1','RX3V3C2','RX3V3C3','RX3V3C4',\n",
    "    'RX4V3C1','RX4V3C2','RX4V3C3','RX4V3C4',\n",
    "    'RX5V3C1','RX5V3C2','RX5V3C3','RX5V3C4',\n",
    "    'RX6V3C1','RX6V3C2','RX6V3C3','RX6V3C4',\n",
    "    'RX7V3C1','RX7V3C2','RX7V3C3','RX7V3C4',\n",
    "    'RX8V3C1','RX8V3C2','RX8V3C3','RX8V3C4',\n",
    "    'RX9V3C1','RX9V3C2','RX9V3C3','RX9V3C4',\n",
    "    'RX10V3C1','RX10V3C2','RX10V3C3','RX10V3C4',\n",
    "    'RX11V3C1','RX11V3C2','RX11V3C3','RX11V3C4',\n",
    "    'RX12V3C1','RX12V3C2','RX12V3C3','RX12V3C4'\n",
    "]\n",
    "\n",
    "addl_drug_cols = [\n",
    "    'PRESCR1','CONTSUB1','COMSTAT1','RX1CAT1','RX1CAT2',\n",
    "    'RX1CAT3','RX1CAT4','PRESCR2','CONTSUB2','COMSTAT2',\n",
    "    'RX2CAT1','RX2CAT2','RX2CAT3','RX2CAT4','PRESCR3','CONTSUB3',\n",
    "    'COMSTAT3','RX3CAT1','RX3CAT2','RX3CAT3','RX3CAT4','PRESCR4',\n",
    "    'CONTSUB4','COMSTAT4','RX4CAT1','RX4CAT2','RX4CAT3',\n",
    "    'RX4CAT4','PRESCR5','CONTSUB5','COMSTAT5','RX5CAT1',\n",
    "    'RX5CAT2','RX5CAT3','RX5CAT4','PRESCR6','CONTSUB6',\n",
    "    'COMSTAT6','RX6CAT1','RX6CAT2','RX6CAT3','RX6CAT4','PRESCR7',\n",
    "    'CONTSUB7','COMSTAT7','RX7CAT1','RX7CAT2','RX7CAT3',\n",
    "    'RX7CAT4','PRESCR8','CONTSUB8','COMSTAT8','RX8CAT1',\n",
    "    'RX8CAT2','RX8CAT3','RX8CAT4','PRESCR9','CONTSUB9',\n",
    "    'COMSTAT9','RX9CAT1','RX9CAT2','RX9CAT3','RX9CAT4',\n",
    "    'PRESCR10','CONTSUB10','COMSTAT10','RX10CAT1','RX10CAT2',\n",
    "    'RX10CAT3','RX10CAT4','PRESCR11','CONTSUB11','COMSTAT11',\n",
    "    'RX11CAT1','RX11CAT2','RX11CAT3','RX11CAT4','PRESCR12',\n",
    "    'CONTSUB12','COMSTAT12','RX12CAT1','RX12CAT2','RX12CAT3',\n",
    "    'RX12CAT4'\n",
    "]\n",
    "\n",
    "X_train.drop(drug_id_cols, axis=1, inplace=True)\n",
    "X_train.drop(drug_lev1_cols, axis=1, inplace=True)\n",
    "X_train.drop(drug_lev2_cols, axis=1, inplace=True)\n",
    "X_train.drop(drug_lev3_cols, axis=1, inplace=True)\n",
    "X_train.drop(addl_drug_cols, axis=1, inplace=True)\n",
    "\n",
    "X_test.drop(drug_id_cols, axis=1, inplace=True)\n",
    "X_test.drop(drug_lev1_cols, axis=1, inplace=True)\n",
    "X_test.drop(drug_lev2_cols, axis=1, inplace=True)\n",
    "X_test.drop(drug_lev3_cols, axis=1, inplace=True)\n",
    "X_test.drop(addl_drug_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94e771c027f055f8996e27051a6e35cd0df17b9e"
   },
   "source": [
    "### Miscellaneous information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "_uuid": "ad39da4d3e5087bb9d0d8e654b638b75c992d371"
   },
   "outputs": [],
   "source": [
    "design_cols = ['CSTRATM','CPSUM','PATWT','EDWT']\n",
    "\n",
    "X_train.drop(design_cols, axis=1, inplace=True)\n",
    "X_test.drop(design_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b3c422f61e945f23278b0563a74507069c0e1b2"
   },
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "_uuid": "41fed64f441a0357a804ecdbf68e19b438480a2a"
   },
   "outputs": [],
   "source": [
    "categ_cols = df_helper.loc[\n",
    "    df_helper['variable_type'] == 'CATEGORICAL', 'column_name'\n",
    "]\n",
    "\n",
    "one_hot_cols = list(set(categ_cols) & set(X_train.columns))\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=one_hot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "_uuid": "4511252118f0eb6dbf91b9b8da0b451004129ddd"
   },
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns=one_hot_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a05c91680c186283e88ccb7410aa53919c9754ed"
   },
   "source": [
    "### Numeric conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "_uuid": "989abebb4a0e0f377d6e0cc7955458e4e05c77be"
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,X_train.columns] = X_train.loc[:,X_train.columns].apply(pd.to_numeric)\n",
    "X_test.loc[:,X_test.columns] = X_test.loc[:,X_test.columns].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e846d45c4315fb148cddaa3f9e1607e27e216a43"
   },
   "source": [
    "### NumPy array conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "_uuid": "e90b56b1b8590769da51e1f62c31d5f1a57d1f20"
   },
   "outputs": [],
   "source": [
    "X_train_cols = X_train.columns\n",
    "X_test_cols = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "_uuid": "b5affd051e464b3d980dbc4e56aeab6a0f73a7be"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70c2d97029bcfe66fb2206a6da7925a08c63c401"
   },
   "source": [
    "# Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b67cbc31ada913484d39e16756d08925fc02bca"
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "_uuid": "a002eaf4ca7f9f05332ddf60f420667eb95dec62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "Training accuracy: 0.8860187278010978\n",
      "Validation accuracy: 0.886682808716707\n",
      "                                                column      coef\n",
      "346                     rfv_Symptoms_of_onset_of_labor  2.066923\n",
      "108  rfv_Other_symptoms_or_problems_relating_to_psy...  1.388934\n",
      "520  rfv_General_psychiatric_or_psychological_exami...  1.235171\n",
      "688                                rfv_Suicide_attempt  1.031974\n",
      "795                                          IMMEDR_01  0.899332\n",
      "201         rfv_Labored_or_difficult_breathing_dyspnea  0.883669\n",
      "88                                     rfv_Depression_  0.880418\n",
      "796                                          IMMEDR_02  0.820472\n",
      "95                     rfv_Delusions_or_hallucinations  0.808396\n",
      "696                   rfv_Adverse_effect_of_drug_abuse  0.788406\n",
      "55                             rfv_Chest_pain_soreness  0.782589\n",
      "607                         rfv_Medical_Counseling_NOS  0.773309\n",
      "42                                rfv_General_weakness  0.772377\n",
      "712         rfv_For_other_and_unspecified_test_results  0.762062\n",
      "470                        rfv_Cerebrovascular_disease  0.760259\n",
      "500  rfv_Diagnosed_complications_of_pregnancy_and_p...  0.717217\n",
      "197                            rfv_Shortness_of_breath  0.696758\n",
      "253             rfv_Lower_abdominal_pain_cramps_spasms  0.687594\n",
      "89                                rfv_Hostile_behavior  0.612128\n",
      "274                          rfv_Blood_in_stool_melena  0.607879\n",
      "262                                       rfv_Vomiting  0.603609\n",
      "807                                          INCSHX_-8  0.579838\n",
      "257             rfv_Upper_abdominal_pain_cramps_spasms  0.565714\n",
      "251               rfv_Abdominal_pain_cramps_spasms_NOS  0.558172\n",
      "126                            rfv_Weakness_neurologic  0.547310\n",
      "762                                          EDPTOR_01  0.526433\n",
      "689                           rfv_Overdose_intentional  0.520913\n",
      "130  rfv_Other_symptoms_referable_to_the_nervous_sy...  0.517154\n",
      "442                                         rfv_Anemia  0.513453\n",
      "46                                           rfv_Edema  0.509764\n",
      "..                                                 ...       ...\n",
      "247   rfv_Stomach_and_abdominal_pain_cramps_and_spasms -0.370668\n",
      "679                                 rfv_Cardiac_arrest -0.374436\n",
      "811                                          SEEN72_-8 -0.392636\n",
      "834                                         BEDDATA_06 -0.397994\n",
      "872                                          ARREMS_02 -0.401563\n",
      "668                             rfv_Animal_snake_human -0.404164\n",
      "27                                                 DVT -0.408160\n",
      "79                                     rfv_Allergy_NOS -0.408452\n",
      "831                                         BEDDATA_03 -0.411840\n",
      "665                                         rfv_Insect -0.413542\n",
      "569         rfv_Medication_other_and_unspecified_kinds -0.414177\n",
      "760                                          EDPTOR_-8 -0.440686\n",
      "816                                            ONO2_-9 -0.442658\n",
      "806                                       OBSPHYSUN_01 -0.454451\n",
      "643                                  rfv_Foot_and_toes -0.454578\n",
      "753                                        RESIDNCE_02 -0.467236\n",
      "207                        rfv_Nosebleed_epistaxis_NEC -0.486319\n",
      "625                               rfv_Hand_and_fingers -0.519792\n",
      "84                         rfv_Anxiety_and_nervousness -0.527548\n",
      "280                                  rfv_Constipation_ -0.556708\n",
      "783                                          OBSSEP_02 -0.578852\n",
      "571                            rfv_Postoperative_visit -0.652204\n",
      "235                                      rfv_Toothache -0.674104\n",
      "604                      rfv_Suture__insertion_removal -0.715170\n",
      "217                                       rfv_Soreness -0.738374\n",
      "188                                  rfv_Earache_pain_ -0.771876\n",
      "798                                          IMMEDR_04 -0.832928\n",
      "371                                      rfv_Skin_rash -0.877674\n",
      "799                                          IMMEDR_05 -0.998671\n",
      "30                                            LEFTATRI -1.142985\n",
      "\n",
      "[941 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfs = [LogisticRegression()]\n",
    "\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(type(clf))\n",
    "    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n",
    "    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n",
    "    \n",
    "    coefs = {\n",
    "        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n",
    "        'coef': [clf.coef_[0,i] for i in range(len(X_train_cols))]\n",
    "    }\n",
    "    df_coefs = pd.DataFrame(coefs)\n",
    "    print(df_coefs.sort_values('coef', axis=0, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression provide a rubust model with consistancy between the training and test sets. The result of the model is as followes:\n",
    "\n",
    "#### Training accuracy: 0.8860187278010978\n",
    "#### Validation accuracy: 0.886682808716707"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "76dc63a2fe9b22c0efb0ef537654b810ca343449"
   },
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "_uuid": "02f55da05d41762cc5edcb020c6baada5e004c35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.8828087167070218\n",
      "                                                column       imp\n",
      "1                                                  AGE  0.036652\n",
      "13                                               PULSE  0.028601\n",
      "15                                               BPSYS  0.027059\n",
      "16                                              BPDIAS  0.026471\n",
      "12                                               TEMPF  0.024818\n",
      "0                                             WAITTIME  0.024795\n",
      "17                                               POPCT  0.021069\n",
      "14                                               RESPR  0.020226\n",
      "29                                            TOTCHRON  0.017520\n",
      "18                                           PAINSCALE  0.016664\n",
      "872                                          ARREMS_02  0.014394\n",
      "871                                          ARREMS_01  0.014194\n",
      "796                                          IMMEDR_02  0.014148\n",
      "922                                             AGER_6  0.012860\n",
      "839                                          NOCHRON_0  0.011142\n",
      "5                                             PAYMCARE  0.010409\n",
      "817                                            ONO2_01  0.009022\n",
      "108  rfv_Other_symptoms_or_problems_relating_to_psy...  0.008677\n",
      "197                            rfv_Shortness_of_breath  0.008507\n",
      "31                                             SURGDAY  0.007874\n",
      "840                                          NOCHRON_1  0.007683\n",
      "798                                          IMMEDR_04  0.007393\n",
      "55                             rfv_Chest_pain_soreness  0.007193\n",
      "2                                                  SEX  0.006562\n",
      "4                                              PAYPRIV  0.006116\n",
      "34                                               NIGHT  0.006095\n",
      "797                                          IMMEDR_03  0.005618\n",
      "920                                             AGER_4  0.005604\n",
      "23                                                 CHF  0.005454\n",
      "6                                             PAYMCAID  0.005342\n",
      "..                                                 ...       ...\n",
      "319                                     rfv_Infrequent  0.000000\n",
      "321                rfv_Irregularity_of_menstrual_flow_  0.000000\n",
      "701  rfv_Adverse_effects_of_terrorism_and_bioterrorism  0.000000\n",
      "459                               rfv_Refractive_error  0.000000\n",
      "460                                       rfv_Cataract  0.000000\n",
      "461                                       rfv_Glaucoma  0.000000\n",
      "324                    rfv_Scanty_flow_oligomenorrhea_  0.000000\n",
      "465  rfv_Rheumatic_fever_and_chronic_rheumatic_hear...  0.000000\n",
      "615                               rfv_Marital_problems  0.000000\n",
      "613                               rfv_Economic_problem  0.000000\n",
      "452                     rfv_Attention_deficit_disorder  0.000000\n",
      "315     rfv_Other_symptoms_of_male_reproductive_system  0.000000\n",
      "350                     rfv_Postcoital_bleeding_female  0.000000\n",
      "447           rfv_Personality_and_character_disorders_  0.000000\n",
      "700            rfv_Adverse_effects_of_secondhand_smoke  0.000000\n",
      "698                              rfv_Alcohol_poisoning  0.000000\n",
      "301                                           rfv_Mass  0.000000\n",
      "302                        rfv_Symptoms_of_the_kidneys  0.000000\n",
      "436                   rfv_Neoplasm_of_uncertain_nature  0.000000\n",
      "693                                 rfv_Food_poisoning  0.000000\n",
      "692                        rfv_Unintentional_poisoning  0.000000\n",
      "307                      rfv_Lumps_bumps_growths_warts  0.000000\n",
      "683                                       rfv_Drowning  0.000000\n",
      "682                                    rfv_Elder_abuse  0.000000\n",
      "681                               rfv_Battered_spouse_  0.000000\n",
      "675                            rfv_Dead_on_arrival_DOA  0.000000\n",
      "352  rfv_Other_symptoms_referable_to_the_female_rep...  0.000000\n",
      "313                      rfv_Growths_warts_lumps_bumps  0.000000\n",
      "314                              rfv_Itching_jock_itch  0.000000\n",
      "710                      rfv_For_results_of_skin_tests  0.000000\n",
      "\n",
      "[941 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfs_rf = [RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "for clf in clfs_rf:\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(type(clf))\n",
    "    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n",
    "    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n",
    "    \n",
    "    imps = {\n",
    "        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n",
    "        'imp': [clf.feature_importances_[i] for i in range(len(X_train_cols))]\n",
    "    }\n",
    "    df_imps = pd.DataFrame(imps)\n",
    "    print(df_imps.sort_values('imp', axis=0, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The result of Random Forest model is as follows:\n",
    "#### Training accuracy: 1.0\n",
    "#### Validation accuracy: 0.8828087167070218\n",
    "\n",
    "#### Having a training accuracy of 1 indicates overfitting. However, Random Forest is typcally robust and does not overfit the data. Feature importance shows that there are many items with absolutely no effect on the model. We expect that removing these featureas would improve the model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11750d4ac7e2fcf9030015b2a54f7e2c667bb3ff"
   },
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "_uuid": "4ed16fbf288190e9d4b2c77aaef29024f21ff61a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150-unit network:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.46042747\n",
      "Iteration 2, loss = 0.26762774\n",
      "Iteration 3, loss = 0.23099945\n",
      "Iteration 4, loss = 0.20990494\n",
      "Iteration 5, loss = 0.19234417\n",
      "Iteration 6, loss = 0.17454482\n",
      "Iteration 7, loss = 0.15777271\n",
      "Iteration 8, loss = 0.14261363\n",
      "Iteration 9, loss = 0.12760340\n",
      "Iteration 10, loss = 0.11404992\n",
      "Iteration 11, loss = 0.10026963\n",
      "Iteration 12, loss = 0.08864339\n",
      "Iteration 13, loss = 0.07872664\n",
      "Iteration 14, loss = 0.06766217\n",
      "Iteration 15, loss = 0.06049338\n",
      "Iteration 16, loss = 0.05281394\n",
      "Iteration 17, loss = 0.04664527\n",
      "Iteration 18, loss = 0.04040355\n",
      "Iteration 19, loss = 0.03564911\n",
      "Iteration 20, loss = 0.03147428\n",
      "Iteration 21, loss = 0.02752492\n",
      "Iteration 22, loss = 0.02445311\n",
      "Iteration 23, loss = 0.02191182\n",
      "Iteration 24, loss = 0.01964949\n",
      "Iteration 25, loss = 0.01792721\n",
      "Iteration 26, loss = 0.01644273\n",
      "Iteration 27, loss = 0.01412957\n",
      "Iteration 28, loss = 0.01222390\n",
      "Iteration 29, loss = 0.01197503\n",
      "Iteration 30, loss = 0.01027081\n",
      "Iteration 31, loss = 0.00964919\n",
      "Iteration 32, loss = 0.00816741\n",
      "Iteration 33, loss = 0.00848181\n",
      "Iteration 34, loss = 0.00775565\n",
      "Iteration 35, loss = 0.00671114\n",
      "Iteration 36, loss = 0.00643923\n",
      "Iteration 37, loss = 0.00713251\n",
      "Iteration 38, loss = 0.00776674\n",
      "Iteration 39, loss = 0.00734837\n",
      "Iteration 40, loss = 0.00589715\n",
      "Iteration 41, loss = 0.00436986\n",
      "Iteration 42, loss = 0.00478342\n",
      "Iteration 43, loss = 0.00347119\n",
      "Iteration 44, loss = 0.00311100\n",
      "Iteration 45, loss = 0.00397898\n",
      "Iteration 46, loss = 0.00347339\n",
      "Iteration 47, loss = 0.00456574\n",
      "Iteration 48, loss = 0.00449269\n",
      "Iteration 49, loss = 0.00471075\n",
      "Iteration 50, loss = 0.00402545\n",
      "Iteration 51, loss = 0.00368014\n",
      "Iteration 52, loss = 0.00294878\n",
      "Iteration 53, loss = 0.00275852\n",
      "Iteration 54, loss = 0.00246846\n",
      "Iteration 55, loss = 0.00227912\n",
      "Iteration 56, loss = 0.00375872\n",
      "Iteration 57, loss = 0.00244039\n",
      "Iteration 58, loss = 0.00271334\n",
      "Iteration 59, loss = 0.02319259\n",
      "Iteration 60, loss = 0.10750447\n",
      "Iteration 61, loss = 0.12110838\n",
      "Iteration 62, loss = 0.04722503\n",
      "Iteration 63, loss = 0.01223036\n",
      "Iteration 64, loss = 0.00557866\n",
      "Iteration 65, loss = 0.00340293\n",
      "Iteration 66, loss = 0.00317782\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training accuracy: 0.9998923689592079\n",
      "Validation accuracy: 0.8857142857142857\n",
      "100-unit network:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.36246986\n",
      "Iteration 2, loss = 0.25986193\n",
      "Iteration 3, loss = 0.23167331\n",
      "Iteration 4, loss = 0.20980379\n",
      "Iteration 5, loss = 0.19225833\n",
      "Iteration 6, loss = 0.17533651\n",
      "Iteration 7, loss = 0.16078798\n",
      "Iteration 8, loss = 0.14319748\n",
      "Iteration 9, loss = 0.12926094\n",
      "Iteration 10, loss = 0.11454745\n",
      "Iteration 11, loss = 0.10248543\n",
      "Iteration 12, loss = 0.09084019\n",
      "Iteration 13, loss = 0.08104346\n",
      "Iteration 14, loss = 0.07228109\n",
      "Iteration 15, loss = 0.06443965\n",
      "Iteration 16, loss = 0.05622794\n",
      "Iteration 17, loss = 0.05085809\n",
      "Iteration 18, loss = 0.04518165\n",
      "Iteration 19, loss = 0.03955685\n",
      "Iteration 20, loss = 0.03703979\n",
      "Iteration 21, loss = 0.03160814\n",
      "Iteration 22, loss = 0.02916788\n",
      "Iteration 23, loss = 0.02514193\n",
      "Iteration 24, loss = 0.02260722\n",
      "Iteration 25, loss = 0.02058863\n",
      "Iteration 26, loss = 0.01810946\n",
      "Iteration 27, loss = 0.01592094\n",
      "Iteration 28, loss = 0.01407315\n",
      "Iteration 29, loss = 0.01374555\n",
      "Iteration 30, loss = 0.01317764\n",
      "Iteration 31, loss = 0.01174809\n",
      "Iteration 32, loss = 0.01045638\n",
      "Iteration 33, loss = 0.01010027\n",
      "Iteration 34, loss = 0.00922715\n",
      "Iteration 35, loss = 0.00910640\n",
      "Iteration 36, loss = 0.00752953\n",
      "Iteration 37, loss = 0.00874199\n",
      "Iteration 38, loss = 0.00719137\n",
      "Iteration 39, loss = 0.00674455\n",
      "Iteration 40, loss = 0.00731735\n",
      "Iteration 41, loss = 0.00728049\n",
      "Iteration 42, loss = 0.00536227\n",
      "Iteration 43, loss = 0.00515504\n",
      "Iteration 44, loss = 0.00727636\n",
      "Iteration 45, loss = 0.00924246\n",
      "Iteration 46, loss = 0.01396998\n",
      "Iteration 47, loss = 0.01854450\n",
      "Iteration 48, loss = 0.03282670\n",
      "Iteration 49, loss = 0.03254385\n",
      "Iteration 50, loss = 0.02395450\n",
      "Iteration 51, loss = 0.02087012\n",
      "Iteration 52, loss = 0.00967201\n",
      "Iteration 53, loss = 0.00448207\n",
      "Iteration 54, loss = 0.00318456\n",
      "Iteration 55, loss = 0.00296629\n",
      "Iteration 56, loss = 0.00309391\n",
      "Iteration 57, loss = 0.00213307\n",
      "Iteration 58, loss = 0.00263768\n",
      "Iteration 59, loss = 0.00224870\n",
      "Iteration 60, loss = 0.00221940\n",
      "Iteration 61, loss = 0.00256123\n",
      "Iteration 62, loss = 0.00253847\n",
      "Iteration 63, loss = 0.00219194\n",
      "Iteration 64, loss = 0.00239965\n",
      "Iteration 65, loss = 0.00240323\n",
      "Iteration 66, loss = 0.00612026\n",
      "Iteration 67, loss = 0.00312800\n",
      "Iteration 68, loss = 0.00282715\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training accuracy: 0.9997309223980196\n",
      "Validation accuracy: 0.8789346246973365\n",
      "80-unit network:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.35454070\n",
      "Iteration 2, loss = 0.26225834\n",
      "Iteration 3, loss = 0.23671209\n",
      "Iteration 4, loss = 0.21851784\n",
      "Iteration 5, loss = 0.20176831\n",
      "Iteration 6, loss = 0.18600299\n",
      "Iteration 7, loss = 0.17039497\n",
      "Iteration 8, loss = 0.15523305\n",
      "Iteration 9, loss = 0.14114271\n",
      "Iteration 10, loss = 0.12678225\n",
      "Iteration 11, loss = 0.11476329\n",
      "Iteration 12, loss = 0.10208249\n",
      "Iteration 13, loss = 0.09205445\n",
      "Iteration 14, loss = 0.08243933\n",
      "Iteration 15, loss = 0.07208936\n",
      "Iteration 16, loss = 0.06474464\n",
      "Iteration 17, loss = 0.05889930\n",
      "Iteration 18, loss = 0.05399492\n",
      "Iteration 19, loss = 0.04716947\n",
      "Iteration 20, loss = 0.04413791\n",
      "Iteration 21, loss = 0.03860912\n",
      "Iteration 22, loss = 0.03468525\n",
      "Iteration 23, loss = 0.03149394\n",
      "Iteration 24, loss = 0.02844319\n",
      "Iteration 25, loss = 0.02542893\n",
      "Iteration 26, loss = 0.02332205\n",
      "Iteration 27, loss = 0.02125126\n",
      "Iteration 28, loss = 0.01900169\n",
      "Iteration 29, loss = 0.01834657\n",
      "Iteration 30, loss = 0.01587931\n",
      "Iteration 31, loss = 0.01431643\n",
      "Iteration 32, loss = 0.01359381\n",
      "Iteration 33, loss = 0.01295109\n",
      "Iteration 34, loss = 0.01162283\n",
      "Iteration 35, loss = 0.01164475\n",
      "Iteration 36, loss = 0.01094481\n",
      "Iteration 37, loss = 0.00949504\n",
      "Iteration 38, loss = 0.00869908\n",
      "Iteration 39, loss = 0.00784198\n",
      "Iteration 40, loss = 0.00771668\n",
      "Iteration 41, loss = 0.00768119\n",
      "Iteration 42, loss = 0.00827529\n",
      "Iteration 43, loss = 0.00643077\n",
      "Iteration 44, loss = 0.00591885\n",
      "Iteration 45, loss = 0.00642158\n",
      "Iteration 46, loss = 0.00530901\n",
      "Iteration 47, loss = 0.00637992\n",
      "Iteration 48, loss = 0.00540144\n",
      "Iteration 49, loss = 0.00460224\n",
      "Iteration 50, loss = 0.00431330\n",
      "Iteration 51, loss = 0.00470202\n",
      "Iteration 52, loss = 0.00406635\n",
      "Iteration 53, loss = 0.00521328\n",
      "Iteration 54, loss = 0.00474590\n",
      "Iteration 55, loss = 0.00464474\n",
      "Iteration 56, loss = 0.00323811\n",
      "Iteration 57, loss = 0.00337889\n",
      "Iteration 58, loss = 0.00293959\n",
      "Iteration 59, loss = 0.00270071\n",
      "Iteration 60, loss = 0.00239151\n",
      "Iteration 61, loss = 0.00232680\n",
      "Iteration 62, loss = 0.00283000\n",
      "Iteration 63, loss = 0.00470816\n",
      "Iteration 64, loss = 0.00426042\n",
      "Iteration 65, loss = 0.01900725\n",
      "Iteration 66, loss = 0.06538718\n",
      "Iteration 67, loss = 0.07168983\n",
      "Iteration 68, loss = 0.03256886\n",
      "Iteration 69, loss = 0.01364987\n",
      "Iteration 70, loss = 0.00521201\n",
      "Iteration 71, loss = 0.00315521\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training accuracy: 0.9998385534388118\n",
      "Validation accuracy: 0.8774818401937046\n",
      "60-unit network:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.43357381\n",
      "Iteration 2, loss = 0.27888069\n",
      "Iteration 3, loss = 0.24739004\n",
      "Iteration 4, loss = 0.22782233\n",
      "Iteration 5, loss = 0.21412121\n",
      "Iteration 6, loss = 0.20152233\n",
      "Iteration 7, loss = 0.18912834\n",
      "Iteration 8, loss = 0.17768024\n",
      "Iteration 9, loss = 0.16643064\n",
      "Iteration 10, loss = 0.15500260\n",
      "Iteration 11, loss = 0.14202183\n",
      "Iteration 12, loss = 0.13168001\n",
      "Iteration 13, loss = 0.12215761\n",
      "Iteration 14, loss = 0.11166814\n",
      "Iteration 15, loss = 0.10143313\n",
      "Iteration 16, loss = 0.09344256\n",
      "Iteration 17, loss = 0.08525069\n",
      "Iteration 18, loss = 0.07834549\n",
      "Iteration 19, loss = 0.07207005\n",
      "Iteration 20, loss = 0.06564179\n",
      "Iteration 21, loss = 0.06120169\n",
      "Iteration 22, loss = 0.05591804\n",
      "Iteration 23, loss = 0.05146194\n",
      "Iteration 24, loss = 0.04729026\n",
      "Iteration 25, loss = 0.04346369\n",
      "Iteration 26, loss = 0.04028081\n",
      "Iteration 27, loss = 0.03733748\n",
      "Iteration 28, loss = 0.03463643\n",
      "Iteration 29, loss = 0.03126852\n",
      "Iteration 30, loss = 0.02920701\n",
      "Iteration 31, loss = 0.02780134\n",
      "Iteration 32, loss = 0.02537660\n",
      "Iteration 33, loss = 0.02321841\n",
      "Iteration 34, loss = 0.02124148\n",
      "Iteration 35, loss = 0.01950178\n",
      "Iteration 36, loss = 0.01836351\n",
      "Iteration 37, loss = 0.01763937\n",
      "Iteration 38, loss = 0.01708266\n",
      "Iteration 39, loss = 0.01620634\n",
      "Iteration 40, loss = 0.01567419\n",
      "Iteration 41, loss = 0.01342846\n",
      "Iteration 42, loss = 0.01247673\n",
      "Iteration 43, loss = 0.01088337\n",
      "Iteration 44, loss = 0.01029677\n",
      "Iteration 45, loss = 0.00993637\n",
      "Iteration 46, loss = 0.00983135\n",
      "Iteration 47, loss = 0.00915182\n",
      "Iteration 48, loss = 0.00822481\n",
      "Iteration 49, loss = 0.00925170\n",
      "Iteration 50, loss = 0.00844922\n",
      "Iteration 51, loss = 0.00843065\n",
      "Iteration 52, loss = 0.00726845\n",
      "Iteration 53, loss = 0.00640614\n",
      "Iteration 54, loss = 0.00879360\n",
      "Iteration 55, loss = 0.00804193\n",
      "Iteration 56, loss = 0.00735653\n",
      "Iteration 57, loss = 0.00874466\n",
      "Iteration 58, loss = 0.00633616\n",
      "Iteration 59, loss = 0.00899177\n",
      "Iteration 60, loss = 0.00704298\n",
      "Iteration 61, loss = 0.00497770\n",
      "Iteration 62, loss = 0.00644555\n",
      "Iteration 63, loss = 0.00422336\n",
      "Iteration 64, loss = 0.00354746\n",
      "Iteration 65, loss = 0.00387357\n",
      "Iteration 66, loss = 0.00401059\n",
      "Iteration 67, loss = 0.00356447\n",
      "Iteration 68, loss = 0.00322460\n",
      "Iteration 69, loss = 0.00374980\n",
      "Iteration 70, loss = 0.00326441\n",
      "Iteration 71, loss = 0.00321602\n",
      "Iteration 72, loss = 0.00334741\n",
      "Iteration 73, loss = 0.00354014\n",
      "Iteration 74, loss = 0.00629154\n",
      "Iteration 75, loss = 0.00661430\n",
      "Iteration 76, loss = 0.00621599\n",
      "Iteration 77, loss = 0.00391237\n",
      "Iteration 78, loss = 0.00690556\n",
      "Iteration 79, loss = 0.00574434\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training accuracy: 0.9996771068776235\n",
      "Validation accuracy: 0.8789346246973365\n",
      "40-unit network:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.37631294\n",
      "Iteration 2, loss = 0.27670785\n",
      "Iteration 3, loss = 0.25069618\n",
      "Iteration 4, loss = 0.23501113\n",
      "Iteration 5, loss = 0.22176468\n",
      "Iteration 6, loss = 0.21070250\n",
      "Iteration 7, loss = 0.19933209\n",
      "Iteration 8, loss = 0.18843077\n",
      "Iteration 9, loss = 0.17675223\n",
      "Iteration 10, loss = 0.16661278\n",
      "Iteration 11, loss = 0.15574234\n",
      "Iteration 12, loss = 0.14577344\n",
      "Iteration 13, loss = 0.13672148\n",
      "Iteration 14, loss = 0.12788980\n",
      "Iteration 15, loss = 0.11977264\n",
      "Iteration 16, loss = 0.11183530\n",
      "Iteration 17, loss = 0.10408129\n",
      "Iteration 18, loss = 0.09882054\n",
      "Iteration 19, loss = 0.09309868\n",
      "Iteration 20, loss = 0.08651480\n",
      "Iteration 21, loss = 0.08077091\n",
      "Iteration 22, loss = 0.07644392\n",
      "Iteration 23, loss = 0.07087569\n",
      "Iteration 24, loss = 0.06622560\n",
      "Iteration 25, loss = 0.06269006\n",
      "Iteration 26, loss = 0.05816704\n",
      "Iteration 27, loss = 0.05506414\n",
      "Iteration 28, loss = 0.05203494\n",
      "Iteration 29, loss = 0.04873037\n",
      "Iteration 30, loss = 0.04528483\n",
      "Iteration 31, loss = 0.04252240\n",
      "Iteration 32, loss = 0.04048708\n",
      "Iteration 33, loss = 0.03813203\n",
      "Iteration 34, loss = 0.03647118\n",
      "Iteration 35, loss = 0.03362628\n",
      "Iteration 36, loss = 0.03156905\n",
      "Iteration 37, loss = 0.02956951\n",
      "Iteration 38, loss = 0.02813418\n",
      "Iteration 39, loss = 0.02677465\n",
      "Iteration 40, loss = 0.02516037\n",
      "Iteration 41, loss = 0.02386482\n",
      "Iteration 42, loss = 0.02226665\n",
      "Iteration 43, loss = 0.02084093\n",
      "Iteration 44, loss = 0.01964867\n",
      "Iteration 45, loss = 0.01893682\n",
      "Iteration 46, loss = 0.01737472\n",
      "Iteration 47, loss = 0.01689683\n",
      "Iteration 48, loss = 0.01610909\n",
      "Iteration 49, loss = 0.01783461\n",
      "Iteration 50, loss = 0.01460895\n",
      "Iteration 51, loss = 0.01332243\n",
      "Iteration 52, loss = 0.01239244\n",
      "Iteration 53, loss = 0.01153411\n",
      "Iteration 54, loss = 0.01105979\n",
      "Iteration 55, loss = 0.01053743\n",
      "Iteration 56, loss = 0.00990619\n",
      "Iteration 57, loss = 0.01002111\n",
      "Iteration 58, loss = 0.00855312\n",
      "Iteration 59, loss = 0.00946142\n",
      "Iteration 60, loss = 0.00910454\n",
      "Iteration 61, loss = 0.00791385\n",
      "Iteration 62, loss = 0.00767070\n",
      "Iteration 63, loss = 0.00847693\n",
      "Iteration 64, loss = 0.00672902\n",
      "Iteration 65, loss = 0.00629873\n",
      "Iteration 66, loss = 0.00645484\n",
      "Iteration 67, loss = 0.00646657\n",
      "Iteration 68, loss = 0.00850395\n",
      "Iteration 69, loss = 0.00810044\n",
      "Iteration 70, loss = 0.00811932\n",
      "Iteration 71, loss = 0.00638262\n",
      "Iteration 72, loss = 0.00593951\n",
      "Iteration 73, loss = 0.00533894\n",
      "Iteration 74, loss = 0.00499287\n",
      "Iteration 75, loss = 0.00515343\n",
      "Iteration 76, loss = 0.00398579\n",
      "Iteration 77, loss = 0.00434683\n",
      "Iteration 78, loss = 0.00531609\n",
      "Iteration 79, loss = 0.00728488\n",
      "Iteration 80, loss = 0.00438025\n",
      "Iteration 81, loss = 0.00443063\n",
      "Iteration 82, loss = 0.00357522\n",
      "Iteration 83, loss = 0.00305260\n",
      "Iteration 84, loss = 0.00316513\n",
      "Iteration 85, loss = 0.00338865\n",
      "Iteration 86, loss = 0.00503069\n",
      "Iteration 87, loss = 0.00389007\n",
      "Iteration 88, loss = 0.00345648\n",
      "Iteration 89, loss = 0.00318632\n",
      "Iteration 90, loss = 0.00331323\n",
      "Iteration 91, loss = 0.00304922\n",
      "Iteration 92, loss = 0.00297034\n",
      "Iteration 93, loss = 0.00644098\n",
      "Iteration 94, loss = 0.02121684\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training accuracy: 0.9923043805833602\n",
      "Validation accuracy: 0.8669895076674737\n",
      "20-unit network:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.65423207\n",
      "Iteration 2, loss = 0.34671278\n",
      "Iteration 3, loss = 0.29129340\n",
      "Iteration 4, loss = 0.26584909\n",
      "Iteration 5, loss = 0.24997232\n",
      "Iteration 6, loss = 0.23907695\n",
      "Iteration 7, loss = 0.23079262\n",
      "Iteration 8, loss = 0.22356778\n",
      "Iteration 9, loss = 0.21744450\n",
      "Iteration 10, loss = 0.21146149\n",
      "Iteration 11, loss = 0.20560899\n",
      "Iteration 12, loss = 0.20038191\n",
      "Iteration 13, loss = 0.19466724\n",
      "Iteration 14, loss = 0.18971259\n",
      "Iteration 15, loss = 0.18447994\n",
      "Iteration 16, loss = 0.18000950\n",
      "Iteration 17, loss = 0.17433077\n",
      "Iteration 18, loss = 0.16904665\n",
      "Iteration 19, loss = 0.16440944\n",
      "Iteration 20, loss = 0.16018349\n",
      "Iteration 21, loss = 0.15590088\n",
      "Iteration 22, loss = 0.15012856\n",
      "Iteration 23, loss = 0.14618453\n",
      "Iteration 24, loss = 0.14133472\n",
      "Iteration 25, loss = 0.13680620\n",
      "Iteration 26, loss = 0.13328819\n",
      "Iteration 27, loss = 0.12844420\n",
      "Iteration 28, loss = 0.12476082\n",
      "Iteration 29, loss = 0.12115142\n",
      "Iteration 30, loss = 0.11809226\n",
      "Iteration 31, loss = 0.11365508\n",
      "Iteration 32, loss = 0.11041726\n",
      "Iteration 33, loss = 0.10712768\n",
      "Iteration 34, loss = 0.10362079\n",
      "Iteration 35, loss = 0.10122281\n",
      "Iteration 36, loss = 0.09817056\n",
      "Iteration 37, loss = 0.09574029\n",
      "Iteration 38, loss = 0.09292590\n",
      "Iteration 39, loss = 0.09039036\n",
      "Iteration 40, loss = 0.08769651\n",
      "Iteration 41, loss = 0.08554696\n",
      "Iteration 42, loss = 0.08280852\n",
      "Iteration 43, loss = 0.08136161\n",
      "Iteration 44, loss = 0.07922781\n",
      "Iteration 45, loss = 0.07665097\n",
      "Iteration 46, loss = 0.07448482\n",
      "Iteration 47, loss = 0.07295650\n",
      "Iteration 48, loss = 0.07171987\n",
      "Iteration 49, loss = 0.06967534\n",
      "Iteration 50, loss = 0.06826019\n",
      "Iteration 51, loss = 0.06640846\n",
      "Iteration 52, loss = 0.06532741\n",
      "Iteration 53, loss = 0.06341559\n",
      "Iteration 54, loss = 0.06126419\n",
      "Iteration 55, loss = 0.06098799\n",
      "Iteration 56, loss = 0.05858034\n",
      "Iteration 57, loss = 0.05753939\n",
      "Iteration 58, loss = 0.05679289\n",
      "Iteration 59, loss = 0.05546925\n",
      "Iteration 60, loss = 0.05369244\n",
      "Iteration 61, loss = 0.05223620\n",
      "Iteration 62, loss = 0.05154061\n",
      "Iteration 63, loss = 0.05041405\n",
      "Iteration 64, loss = 0.04947869\n",
      "Iteration 65, loss = 0.04841466\n",
      "Iteration 66, loss = 0.04784808\n",
      "Iteration 67, loss = 0.04690213\n",
      "Iteration 68, loss = 0.04510358\n",
      "Iteration 69, loss = 0.04466452\n",
      "Iteration 70, loss = 0.04327865\n",
      "Iteration 71, loss = 0.04199999\n",
      "Iteration 72, loss = 0.04128366\n",
      "Iteration 73, loss = 0.04079477\n",
      "Iteration 74, loss = 0.03963344\n",
      "Iteration 75, loss = 0.03907833\n",
      "Iteration 76, loss = 0.03812851\n",
      "Iteration 77, loss = 0.03731989\n",
      "Iteration 78, loss = 0.03635441\n",
      "Iteration 79, loss = 0.03601185\n",
      "Iteration 80, loss = 0.03498993\n",
      "Iteration 81, loss = 0.03519475\n",
      "Iteration 82, loss = 0.03386994\n",
      "Iteration 83, loss = 0.03299395\n",
      "Iteration 84, loss = 0.03219309\n",
      "Iteration 85, loss = 0.03152654\n",
      "Iteration 86, loss = 0.03059853\n",
      "Iteration 87, loss = 0.03085858\n",
      "Iteration 88, loss = 0.03005536\n",
      "Iteration 89, loss = 0.02853245\n",
      "Iteration 90, loss = 0.02914330\n",
      "Iteration 91, loss = 0.02761192\n",
      "Iteration 92, loss = 0.02746373\n",
      "Iteration 93, loss = 0.02717920\n",
      "Iteration 94, loss = 0.02667792\n",
      "Iteration 95, loss = 0.02554246\n",
      "Iteration 96, loss = 0.02478807\n",
      "Iteration 97, loss = 0.02431518\n",
      "Iteration 98, loss = 0.02413174\n",
      "Iteration 99, loss = 0.02373048\n",
      "Iteration 100, loss = 0.02440447\n",
      "Iteration 101, loss = 0.02336744\n",
      "Iteration 102, loss = 0.02225450\n",
      "Iteration 103, loss = 0.02190692\n",
      "Iteration 104, loss = 0.02172047\n",
      "Iteration 105, loss = 0.02258792\n",
      "Iteration 106, loss = 0.02076552\n",
      "Iteration 107, loss = 0.02007170\n",
      "Iteration 108, loss = 0.02009018\n",
      "Iteration 109, loss = 0.01994816\n",
      "Iteration 110, loss = 0.02013803\n",
      "Iteration 111, loss = 0.01829690\n",
      "Iteration 112, loss = 0.01829868\n",
      "Iteration 113, loss = 0.01789614\n",
      "Iteration 114, loss = 0.01781715\n",
      "Iteration 115, loss = 0.01717801\n",
      "Iteration 116, loss = 0.01628172\n",
      "Iteration 117, loss = 0.01649335\n",
      "Iteration 118, loss = 0.01589627\n",
      "Iteration 119, loss = 0.01572065\n",
      "Iteration 120, loss = 0.01565160\n",
      "Iteration 121, loss = 0.01445764\n",
      "Iteration 122, loss = 0.01458631\n",
      "Iteration 123, loss = 0.01471924\n",
      "Iteration 124, loss = 0.01411187\n",
      "Iteration 125, loss = 0.01488691\n",
      "Iteration 126, loss = 0.01499750\n",
      "Iteration 127, loss = 0.01656935\n",
      "Iteration 128, loss = 0.01364717\n",
      "Iteration 129, loss = 0.01330677\n",
      "Iteration 130, loss = 0.01360345\n",
      "Iteration 131, loss = 0.01249007\n",
      "Iteration 132, loss = 0.01191979\n",
      "Iteration 133, loss = 0.01113554\n",
      "Iteration 134, loss = 0.01076111\n",
      "Iteration 135, loss = 0.01117288\n",
      "Iteration 136, loss = 0.01088375\n",
      "Iteration 137, loss = 0.01081474\n",
      "Iteration 138, loss = 0.01136610\n",
      "Iteration 139, loss = 0.01101740\n",
      "Iteration 140, loss = 0.01027654\n",
      "Iteration 141, loss = 0.01011141\n",
      "Iteration 142, loss = 0.00974027\n",
      "Iteration 143, loss = 0.00881198\n",
      "Iteration 144, loss = 0.00918374\n",
      "Iteration 145, loss = 0.00950146\n",
      "Iteration 146, loss = 0.00893997\n",
      "Iteration 147, loss = 0.00927230\n",
      "Iteration 148, loss = 0.00854539\n",
      "Iteration 149, loss = 0.00912607\n",
      "Iteration 150, loss = 0.00917383\n",
      "Iteration 151, loss = 0.00849462\n",
      "Iteration 152, loss = 0.00804832\n",
      "Iteration 153, loss = 0.00893414\n",
      "Iteration 154, loss = 0.00770727\n",
      "Iteration 155, loss = 0.00929354\n",
      "Iteration 156, loss = 0.00927968\n",
      "Iteration 157, loss = 0.00751206\n",
      "Iteration 158, loss = 0.00841545\n",
      "Iteration 159, loss = 0.00698880\n",
      "Iteration 160, loss = 0.00758957\n",
      "Iteration 161, loss = 0.00708127\n",
      "Iteration 162, loss = 0.00833615\n",
      "Iteration 163, loss = 0.00848127\n",
      "Iteration 164, loss = 0.00829854\n",
      "Iteration 165, loss = 0.00669969\n",
      "Iteration 166, loss = 0.00600389\n",
      "Iteration 167, loss = 0.00632532\n",
      "Iteration 168, loss = 0.00560836\n",
      "Iteration 169, loss = 0.00552574\n",
      "Iteration 170, loss = 0.00503744\n",
      "Iteration 171, loss = 0.00474950\n",
      "Iteration 172, loss = 0.00659419\n",
      "Iteration 173, loss = 0.00790138\n",
      "Iteration 174, loss = 0.00629110\n",
      "Iteration 175, loss = 0.00584463\n",
      "Iteration 176, loss = 0.00579193\n",
      "Iteration 177, loss = 0.00472679\n",
      "Iteration 178, loss = 0.00441045\n",
      "Iteration 179, loss = 0.00448596\n",
      "Iteration 180, loss = 0.00492096\n",
      "Iteration 181, loss = 0.00514689\n",
      "Iteration 182, loss = 0.00792121\n",
      "Iteration 183, loss = 0.00917487\n",
      "Iteration 184, loss = 0.01083542\n",
      "Iteration 185, loss = 0.01081117\n",
      "Iteration 186, loss = 0.00840770\n",
      "Iteration 187, loss = 0.00579063\n",
      "Iteration 188, loss = 0.00423531\n",
      "Iteration 189, loss = 0.00385730\n",
      "Iteration 190, loss = 0.00404896\n",
      "Iteration 191, loss = 0.00402171\n",
      "Iteration 192, loss = 0.00341135\n",
      "Iteration 193, loss = 0.00366555\n",
      "Iteration 194, loss = 0.00399097\n",
      "Iteration 195, loss = 0.00355298\n",
      "Iteration 196, loss = 0.00390864\n",
      "Iteration 197, loss = 0.00486513\n",
      "Iteration 198, loss = 0.00432274\n",
      "Iteration 199, loss = 0.00471670\n",
      "Iteration 200, loss = 0.00562210\n",
      "Training accuracy: 0.9995694758368313\n",
      "Validation accuracy: 0.8561743341404359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train) \n",
    "X_train_Tx = scaler.transform(X_train) \n",
    "X_test_Tx = scaler.transform(X_test) \n",
    "\n",
    "# Fit models that require scaling (e.g. neural networks)\n",
    "hl_sizes = [150,100,80,60,40,20]\n",
    "nn_clfs = [MLPClassifier(hidden_layer_sizes=(size,), random_state=2345, verbose=True) for size in hl_sizes]\n",
    "\n",
    "for num, nn_clf in enumerate(nn_clfs):\n",
    "    print(str(hl_sizes[num]) + '-unit network:')\n",
    "    nn_clf.fit(X_train_Tx, y_train)\n",
    "    print('Training accuracy: ' + str(nn_clf.score(X_train_Tx, y_train)))\n",
    "    print('Validation accuracy: ' + str(nn_clf.score(X_test_Tx, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 layers resulted in \n",
    "#### Training accuracy: 0.9996771068776235\n",
    "#### Validation accuracy: 0.8789346246973365\n",
    "#### Training accuracy indicates that our model is overfitting and that could be due to the large number of features the data contains. In addition, the training set has approximately 18,000 observations, for neural network models to perform well typically much lareger amount of observations are needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f5cadb387c780e321f0710dc3b0ed6d1f4bccaf"
   },
   "source": [
    "#### In this project we have built a model that could pridict the Emergency Department visits resulting in Hospital Admission with 88.60% accuracy on test data. \n",
    "#### The model performance can be improved by performing some feature selection methods. \n",
    "#### The model can help the hospitals to improve the management of their resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

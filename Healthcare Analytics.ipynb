{
  "cells": [
    {
      "metadata": {
        "_uuid": "3908bb2d1e246f5877127a9419f6fc4e77e0ddb4"
      },
      "cell_type": "markdown",
      "source": "## Predicting discharge statuses for patients presenting to the emergency room"
    },
    {
      "metadata": {
        "_uuid": "299e661498a7a628a96e1162f3ec8019498ddb05"
      },
      "cell_type": "markdown",
      "source": "Management of the resources of emergency department facilities based on the number of the patients plays an important role in performance of the hospital by reducing cost and increasing the quality of care.  A large influx of patients at any given time could result in shortage of staff and lack of available rooms.\n\nIn this context, predicting the outcome of the emergency department visit, whether the patient is admitted to the hospital or sent home,  early on in the patient stay is the objective of this project. \n\nThe dataset selected for this study is part of the National Hospital Ambulatory Medical Care Survey (NHAMCS) public use data by the US Center for Disease Control and Prevention (CDC). "
    },
    {
      "metadata": {
        "_uuid": "2d36425f3f237136ff5c87ba6ce537bf808edbc5"
      },
      "cell_type": "markdown",
      "source": "### Reading data in a fixed-width format (fwf)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a64d485539cc2673304882717256fa30153f27b"
      },
      "cell_type": "code",
      "source": "import pandas as pd\npd.set_option('mode.chained_assignment',None)\n\ndf_helper = pd.read_csv(\n    '../input/metadata/ED_metadata.csv',\n    header=0, \n    dtype={'width': int, 'column_name': str, 'variable_type': str}\n)\nprint(df_helper.head(n=5))",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": "   width column_name  variable_type\n0      2      VMONTH    CATEGORICAL\n1      1       VDAYR    CATEGORICAL\n2      4     ARRTIME  NONPREDICTIVE\n3      4    WAITTIME     CONTINUOUS\n4      4         LOV  NONPREDICTIVE\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1893cc50fe7d47dfbf722dd8859ed4de9a27df90"
      },
      "cell_type": "code",
      "source": "width = df_helper['width'].tolist()\ncol_names = df_helper['column_name'].tolist()\nvar_types = df_helper['variable_type'].tolist()",
      "execution_count": 65,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de164d1340f3eca072adad7aa0bedf1203c91bd1"
      },
      "cell_type": "code",
      "source": "df= pd.read_fwf(\n    '../input/healthcare/ED2013',\n    widths=width,\n    header=None,\n    dtype='str'  \n)",
      "execution_count": 66,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "13bc2999964ba64ded6e3f4eafc74b33152d7c70"
      },
      "cell_type": "code",
      "source": "df.columns = col_names",
      "execution_count": 67,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75c6c9dcddde37bc656184d54eff7d9c38b57b57"
      },
      "cell_type": "code",
      "source": "print(df.tail(n=5))",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": "      VMONTH VDAYR ARRTIME WAITTIME ...    CSTRATM   CPSUM   PATWT EDWT\n24772     08     1    1925     0000 ...   40300000  000023  003043  nan\n24773     08     1    0929     0000 ...   40300000  000023  003043  nan\n24774     07     1    0116     0000 ...   40300000  000023  003043  nan\n24775     07     7    1300     0000 ...   40300000  000023  003043  nan\n24776     07     6    2335     0045 ...   40300000  000023  003043  nan\n\n[5 rows x 579 columns]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c90c1c9aa45bcbe2d317744ec873d671f6ee6f9c"
      },
      "cell_type": "code",
      "source": "# print(list(df.columns))",
      "execution_count": 69,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b6678901f8e92b43fa14c9ce8db5c9c15c84facc"
      },
      "cell_type": "code",
      "source": "print(df.shape)",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(24777, 579)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "081a71cd5e5fe59f33c519600667d32574fe794d"
      },
      "cell_type": "code",
      "source": "df['ADMITHOS'].value_counts()",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "0    22304\n1     2473\nName: ADMITHOS, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "6f7f8e74d34567cae936dc186608061b29bb8c64"
      },
      "cell_type": "markdown",
      "source": "## Target Variable\n\nIn this project, we are trying to predict which patients presenting to the ED will eventually be hospitalized.\n\nIn this case, hospitalization encompasses:\n\na) Those admitted to an inpatient ward for further evaluation and treatment\n\nb) Those transferred to a different hospital (either psychiatric or non-psychiatric) for further treatment\n\nc) Those admitted to the observation unit for further evaluation (whether they are eventually admitted or discharged after their observation unit stay)\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75ea4467d4a79ee8f8c3d0769c96d3e5bd0694ad"
      },
      "cell_type": "code",
      "source": "target_cols = ['ADMITHOS','TRANOTH','TRANPSYC','OBSHOS','OBSDIS']",
      "execution_count": 72,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "409172909ba6999cb34a5a14f713d0072a5b966c"
      },
      "cell_type": "raw",
      "source": "def missing(data, target_columns):\n    for col in target_columns:\n        data[col]=data[col].replace(['-','7','8','9'],'nan')\n    return (data, target_columns)"
    },
    {
      "metadata": {
        "_uuid": "830a6469201db460977cdfb2086b7fd51eb9c728"
      },
      "cell_type": "raw",
      "source": "df, target_cols= missing(df,target_cols)"
    },
    {
      "metadata": {
        "_uuid": "2f2ef72bdb8c49696458b19dceda28b5f7d8ac72"
      },
      "cell_type": "raw",
      "source": "df.loc[:, target_cols] = df.loc[:, target_cols].apply(pd.to_numeric, errors='coerce')\ndf.loc[:, target_cols] = df.loc[:, target_cols].apply(pd.to_numeric,  errors='coerce')"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f458e9fa6ded5c4543c01928686e198f7e4a5e36"
      },
      "cell_type": "code",
      "source": "df.loc[:, target_cols] = df.loc[:, target_cols].apply(pd.to_numeric)\ndf.loc[:, target_cols] = df.loc[:, target_cols].apply(pd.to_numeric)\n\ndf['ADMITTEMP'] = df[target_cols].sum(axis=1)\n\ndf['ADMITFINAL'] = 0\ndf.loc[df['ADMITTEMP'] >= 1, 'ADMITFINAL'] = 1\n\ndf.drop(target_cols, axis=1, inplace=True)\ndf.drop('ADMITTEMP', axis=1, inplace=True)",
      "execution_count": 73,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e3e73d5db7b356111095608911cdbd3a365412bc"
      },
      "cell_type": "markdown",
      "source": "## Train and Test Split"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d4bf0a9b3744725cd0cef7e52dbc02fa32c1566"
      },
      "cell_type": "code",
      "source": "def split_target(data, target_name):\n    target = data[[target_name]]\n    data.drop(target_name, axis=1, inplace=True)\n    return (data, target)\n\nX, y = split_target(df, 'ADMITFINAL')",
      "execution_count": 74,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a8393233a992a35b1de2f1320471ab954ffac6c"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=123\n)",
      "execution_count": 75,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8517d49d9d5ec1c052bdc5a6ad2f0525db690cf"
      },
      "cell_type": "code",
      "source": "print(y_train.groupby('ADMITFINAL').size())",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": "ADMITFINAL\n0    16028\n1     2554\ndtype: int64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "85509ecc43b5b3dc8435883cb7e1c484faaf276a"
      },
      "cell_type": "markdown",
      "source": "## Preprocessing the Predictor Variables"
    },
    {
      "metadata": {
        "_uuid": "076ba4a9458e53e5781ccf86af0a5b9b2a3e62fb"
      },
      "cell_type": "markdown",
      "source": "### Visit information"
    },
    {
      "metadata": {
        "_uuid": "aa55ba1b0774385ef5648b6affb1c7d5ecaaec14"
      },
      "cell_type": "markdown",
      "source": "#### Month"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98fc8534e609597e08cdf8647700cedd3ecd6425"
      },
      "cell_type": "code",
      "source": "print(X_train.groupby('VMONTH').size())",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": "VMONTH\n01    1780\n02    1369\n03    1433\n04    1705\n05    2034\n06    1716\n07    1768\n08    1038\n09    1225\n10    1273\n11    1669\n12    1572\ndtype: int64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2dc8d723bb04bb980da0c3eeb8344b8d75a15eb7"
      },
      "cell_type": "code",
      "source": "def is_winter(vmonth):\n    if vmonth in ['12','01','02','03']:\n        return 1\n    else:\n        return 0\n    \nX_train.loc[:,'WINTER'] = df.loc[:,'VMONTH'].apply(is_winter)\nX_test.loc[:,'WINTER'] = df.loc[:,'VMONTH'].apply(is_winter)",
      "execution_count": 78,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e30028ccd8d4ea9ef6aa9052a0d1df0760ec9f5a"
      },
      "cell_type": "markdown",
      "source": "#### Day"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45b4cc95e8bb614c4e3026a5ff9eb6c20525b632"
      },
      "cell_type": "code",
      "source": "X_train.groupby('VDAYR').size()",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 79,
          "data": {
            "text/plain": "VDAYR\n1    2576\n2    2959\n3    2775\n4    2655\n5    2529\n6    2545\n7    2543\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b821795fafa58c4244b1e1d8cef935124dec9e34"
      },
      "cell_type": "markdown",
      "source": "#### Arrival Time"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "be53538a22e0304219feeb3d7052cccde377d0c1"
      },
      "cell_type": "code",
      "source": "def is_night(arrtime):\n    arrtime_int = int(arrtime)\n    if ((arrtime_int >= 0) & (arrtime_int < 800)):\n        return 1\n    elif ((arrtime_int >= 2000) & (arrtime_int < 2400)):\n        return 1\n    else:\n        return 0\n    \nX_train.loc[:,'NIGHT'] = df.loc[:,'ARRTIME'].apply(is_night)\nX_test.loc[:,'NIGHT'] = df.loc[:,'ARRTIME'].apply(is_night)\n\nX_train.drop('ARRTIME', axis=1, inplace=True)\nX_test.drop('ARRTIME', axis=1, inplace=True)",
      "execution_count": 80,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "79a1617458e8dba040930ea885af78abcf2da47b"
      },
      "cell_type": "markdown",
      "source": "#### Wait Time"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9fd5f635260f47bb470dcec237b876086af46ad"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'WAITTIME'] = X_train.loc[:,'WAITTIME'].apply(pd.to_numeric)\nX_test.loc[:,'WAITTIME'] = X_test.loc[:,'WAITTIME'].apply(pd.to_numeric)",
      "execution_count": 81,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7e3f6fe2860a0d0dde7a6122f9189255fd30874a"
      },
      "cell_type": "markdown",
      "source": "### Mean Imputation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a2454961999bd2ae1e50a675d0861910abe346fe"
      },
      "cell_type": "code",
      "source": "# Mean imputation In the documentation\n# The WAITTIME variable may take values of -9 and -7 when blank and not applicable, respectively. \n\ndef mean_impute_values(data,col):  \n    temp_mean = data.loc[(data[col] != -7) & (data[col] != -9), col].mean()\n    data.loc[(data[col] == -7) | (data[col] == -9), col] = temp_mean            \n    return data\n\nX_train = mean_impute_values(X_train,'WAITTIME')\nX_test = mean_impute_values(X_test,'WAITTIME')",
      "execution_count": 82,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2afa1e8ef5075d1f5717af8385511aad3179816e"
      },
      "cell_type": "markdown",
      "source": "#### Dropping other visit variables"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b372a7e4fa6ffcdb5d16a4e42710da70528b430b"
      },
      "cell_type": "code",
      "source": "X_train.drop('LOV', axis=1, inplace=True)\nX_test.drop('LOV', axis=1, inplace=True)",
      "execution_count": 83,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9f26805c0c94eb45d716a884d27b7117075662ae"
      },
      "cell_type": "markdown",
      "source": "## Demographic Variables"
    },
    {
      "metadata": {
        "_uuid": "1df08d257ad6e15e5268a9643c5e3b5de22f761e"
      },
      "cell_type": "markdown",
      "source": "#### Age"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30846a1165f2f4f3170e29f93cb76cc0065a2166"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'AGE'] = X_train.loc[:,'AGE'].apply(pd.to_numeric)\nX_test.loc[:,'AGE'] = X_test.loc[:,'AGE'].apply(pd.to_numeric)\n\nX_train.drop('AGEDAYS', axis=1, inplace=True)\nX_test.drop('AGEDAYS', axis=1, inplace=True)",
      "execution_count": 84,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2d1023ad970ceb182c116bd1b1564ab7798cfca0"
      },
      "cell_type": "markdown",
      "source": "#### Sex\n\nWe keep the sex column as it is."
    },
    {
      "metadata": {
        "_uuid": "7fdeabc32e96cf4885e803e296f122eec3b4ee8d"
      },
      "cell_type": "markdown",
      "source": "#### Ethnicity and race\nWe leave the unimputed ethnicity and race variables (ETHUN and RACEUN) as is."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b804171169a44d85477cf2f83c6a14f8b9603caf"
      },
      "cell_type": "code",
      "source": "X_train.drop(['ETHIM','RACER','RACERETH'], axis=1, inplace=True)\nX_test.drop(['ETHIM','RACER','RACERETH'], axis=1, inplace=True)",
      "execution_count": 85,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c1894b4c5f5f49312044f68cbe28029302b6b272"
      },
      "cell_type": "markdown",
      "source": "## Triage Variables"
    },
    {
      "metadata": {
        "_uuid": "2805ca669e59d85cbe4443022407571d85190384"
      },
      "cell_type": "markdown",
      "source": "The IMMEDR variable represents the triage scores that range from 1 (critical) to 5 (non-urgent). \n\nARREMS that shows whether or not the patient arrived via EMS and SEEN72 that indecate whether or not the patient has been seen and discharged within the last 72 hours (SEEN72) will also get included in our model."
    },
    {
      "metadata": {
        "_uuid": "740b5ea408d994bf1f855342e9cf41e0b940a4e2"
      },
      "cell_type": "markdown",
      "source": "## Financial Variables"
    },
    {
      "metadata": {
        "_uuid": "332c5a5c7b9682cd9aa3bc2fef53e219d4b8e480"
      },
      "cell_type": "markdown",
      "source": "We include all of the financial variables in our model except for the PAYTYPER variable, which is a nonbinary expansion of the other payment variables."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40ad758bacaf1292ba8dce86285d3ededab50e2f"
      },
      "cell_type": "code",
      "source": "X_train.drop('PAYTYPER', axis=1, inplace=True)\nX_test.drop('PAYTYPER', axis=1, inplace=True)",
      "execution_count": 86,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a0b722584cb74d277755b8ca6f97185fe25dc83f"
      },
      "cell_type": "markdown",
      "source": "## Vital Signs"
    },
    {
      "metadata": {
        "_uuid": "06352e494b5961b4d2afcf64c7d7de31e7223c87"
      },
      "cell_type": "markdown",
      "source": "#### Temperature\n\nIn the dataset all temoratures are multiplied by 10 so we need to devide them by 10."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e185294147754b8739aede96701bf4776a93fe2"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'TEMPF'] = X_train.loc[:,'TEMPF'].apply(pd.to_numeric)\nX_test.loc[:,'TEMPF'] = X_test.loc[:,'TEMPF'].apply(pd.to_numeric)\n\nX_train = mean_impute_values(X_train,'TEMPF')\nX_test = mean_impute_values(X_test,'TEMPF')\n\nX_train.loc[:,'TEMPF'] = X_train.loc[:,'TEMPF'].apply(lambda x: float(x)/10)\nX_test.loc[:,'TEMPF'] = X_test.loc[:,'TEMPF'].apply(lambda x: float(x)/10)",
      "execution_count": 87,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae95e0826b0565e5c1f3a1b6bbad8283edf6036b"
      },
      "cell_type": "code",
      "source": "X_train['TEMPF'].head(n=10)",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 88,
          "data": {
            "text/plain": "4232     98.7\n20594    98.1\n10153    98.7\n15805    98.4\n18066    98.0\n6497     98.4\n5395     98.4\n13974    98.3\n9200     97.5\n12244    99.5\nName: TEMPF, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "a47ab2899bde0f678219fdf45857b09ac680cdbd"
      },
      "cell_type": "markdown",
      "source": "#### Pulse"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2bfaaf85f7f64ec369842e6b3039bcdf91e6a5d8"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'PULSE'] = X_train.loc[:,'PULSE'].apply(pd.to_numeric)\nX_test.loc[:,'PULSE'] = X_test.loc[:,'PULSE'].apply(pd.to_numeric)",
      "execution_count": 89,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f27a0d95378e0b4d842c1c26b8a347270c671068"
      },
      "cell_type": "code",
      "source": "def mean_impute_vitals(data,col): \n    temp_mean = data.loc[(data[col] != 998) & (data[col] != -9), col].mean()\n    data.loc[(data[col] == 998) | (data[col] == -9), col] = temp_mean \n    return data\n\nX_train = mean_impute_vitals(X_train,'PULSE')\nX_test = mean_impute_vitals(X_test,'PULSE')",
      "execution_count": 90,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5e51744e4ce0eaaefa091fd4764cb5dbe70c5071"
      },
      "cell_type": "markdown",
      "source": "#### Respiratory Rate"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "956d8e5250e051ecc9b186956b5ee262f0724410"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'RESPR'] = X_train.loc[:,'RESPR'].apply(pd.to_numeric)\nX_test.loc[:,'RESPR'] = X_test.loc[:,'RESPR'].apply(pd.to_numeric)\n\nX_train = mean_impute_values(X_train,'RESPR')\nX_test = mean_impute_values(X_test,'RESPR')",
      "execution_count": 91,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b47794c42b8043814a6e388bfbaba0f9370c8c6d"
      },
      "cell_type": "markdown",
      "source": "#### Blood pressure"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "574e8fe38c2de50dd4c3c44a77065ce56c129c1b"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'BPSYS'] = X_train.loc[:,'BPSYS'].apply(pd.to_numeric)\nX_test.loc[:,'BPSYS'] = X_test.loc[:,'BPSYS'].apply(pd.to_numeric)\n\nX_train = mean_impute_values(X_train,'BPSYS')\nX_test = mean_impute_values(X_test,'BPSYS')",
      "execution_count": 92,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7d738c7e73562b6dca470427392ee87deec69f08"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'BPDIAS'] = X_train.loc[:,'BPDIAS'].apply(pd.to_numeric)\nX_test.loc[:,'BPDIAS'] = X_test.loc[:,'BPDIAS'].apply(pd.to_numeric)",
      "execution_count": 93,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "50de3520a3ab0e3fa459831576103d40eb6584a6"
      },
      "cell_type": "code",
      "source": "def mean_impute_bp_diast(data,col): \n    temp_mean = data.loc[(data[col] != 998) & (data[col] != -9), col].mean()\n    data.loc[data[col] == 998, col] = 40\n    data.loc[data[col] == -9, col] = temp_mean \n    return data\n\nX_train = mean_impute_values(X_train,'BPDIAS')\nX_test = mean_impute_values(X_test,'BPDIAS')",
      "execution_count": 94,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9457200d765fac08b555b45f7ca60d87a8546100"
      },
      "cell_type": "markdown",
      "source": "#### Oxygen saturation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e3b3faeb81864e48171a140399a6189e4bc6086"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'POPCT'] = X_train.loc[:,'POPCT'].apply(pd.to_numeric)\nX_test.loc[:,'POPCT'] = X_test.loc[:,'POPCT'].apply(pd.to_numeric)\n\nX_train = mean_impute_values(X_train,'POPCT')\nX_test = mean_impute_values(X_test,'POPCT')",
      "execution_count": 95,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "49faa1122aab0c4e15aacdab724d118831134689"
      },
      "cell_type": "code",
      "source": "X_train[['TEMPF','PULSE','RESPR','BPSYS','BPDIAS','POPCT']].head(n=10)",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 96,
          "data": {
            "text/plain": "       TEMPF  PULSE      RESPR  BPSYS  BPDIAS  POPCT\n4232    98.7   73.0  20.000000  118.0    61.0  100.0\n20594   98.1   86.0  20.000000  148.0    85.0   98.0\n10153   98.7   98.0  28.000000  160.0   106.0  100.0\n15805   98.4   75.0  19.568148  111.0    58.0  100.0\n18066   98.0  109.0  18.000000  199.0   111.0   94.0\n6497    98.4   88.0  16.000000  169.0    85.0   95.0\n5395    98.4  152.0  40.000000  125.0    77.0   95.0\n13974   98.3  115.0  22.000000  133.0    73.0   96.0\n9200    97.5   81.0  18.000000  140.0    68.0   96.0\n12244   99.5  110.0  20.000000  158.0   107.0  100.0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TEMPF</th>\n      <th>PULSE</th>\n      <th>RESPR</th>\n      <th>BPSYS</th>\n      <th>BPDIAS</th>\n      <th>POPCT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4232</th>\n      <td>98.7</td>\n      <td>73.0</td>\n      <td>20.000000</td>\n      <td>118.0</td>\n      <td>61.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>20594</th>\n      <td>98.1</td>\n      <td>86.0</td>\n      <td>20.000000</td>\n      <td>148.0</td>\n      <td>85.0</td>\n      <td>98.0</td>\n    </tr>\n    <tr>\n      <th>10153</th>\n      <td>98.7</td>\n      <td>98.0</td>\n      <td>28.000000</td>\n      <td>160.0</td>\n      <td>106.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>15805</th>\n      <td>98.4</td>\n      <td>75.0</td>\n      <td>19.568148</td>\n      <td>111.0</td>\n      <td>58.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>18066</th>\n      <td>98.0</td>\n      <td>109.0</td>\n      <td>18.000000</td>\n      <td>199.0</td>\n      <td>111.0</td>\n      <td>94.0</td>\n    </tr>\n    <tr>\n      <th>6497</th>\n      <td>98.4</td>\n      <td>88.0</td>\n      <td>16.000000</td>\n      <td>169.0</td>\n      <td>85.0</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>5395</th>\n      <td>98.4</td>\n      <td>152.0</td>\n      <td>40.000000</td>\n      <td>125.0</td>\n      <td>77.0</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>13974</th>\n      <td>98.3</td>\n      <td>115.0</td>\n      <td>22.000000</td>\n      <td>133.0</td>\n      <td>73.0</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>9200</th>\n      <td>97.5</td>\n      <td>81.0</td>\n      <td>18.000000</td>\n      <td>140.0</td>\n      <td>68.0</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>12244</th>\n      <td>99.5</td>\n      <td>110.0</td>\n      <td>20.000000</td>\n      <td>158.0</td>\n      <td>107.0</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "291435580e46b82cfe646cb7811bb1c3f7b50c85"
      },
      "cell_type": "markdown",
      "source": "#### Pain level"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6c94534630ab1a5942869ac891a9dae73d00a79"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'PAINSCALE'] = X_train.loc[:,'PAINSCALE'].apply(pd.to_numeric)\nX_test.loc[:,'PAINSCALE'] = X_test.loc[:,'PAINSCALE'].apply(pd.to_numeric)",
      "execution_count": 97,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "242720cd1a203fc14108954f93caacbb8de71fbd"
      },
      "cell_type": "code",
      "source": "def mean_impute_pain(data,col): \n    temp_mean = data.loc[(data[col] != -8) & (data[col] != -9), col].mean()\n    data.loc[(data[col] == -8) | (data[col] == -9), col] = temp_mean \n    return data\n\nX_train = mean_impute_pain(X_train,'PAINSCALE')\nX_test = mean_impute_pain(X_test,'PAINSCALE')",
      "execution_count": 98,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d051bf29d03d211d90cda64d40507140bce85068"
      },
      "cell_type": "markdown",
      "source": "### Reason-for-visit codes"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2bade0c202928960905ac059d7de91d4e8cb3086"
      },
      "cell_type": "code",
      "source": "rfv_codes_path = '../input/rfv-codes/RFV_CODES.csv'\n\nrfv_codes = pd.read_csv(rfv_codes_path,header=0,dtype='str')",
      "execution_count": 99,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "99fc2e635dbe79175cf950e4d8b15b760c4f6f88"
      },
      "cell_type": "code",
      "source": "from re import sub\n\ndef add_rfv_column(data,code,desc,rfv_columns):\n    column_name = 'rfv_' + sub(\" \", \"_\", desc)\n    data[column_name] = (data[rfv_columns] == rfv_code).any(axis=1).astype('int')\n    return data\n\nrfv_columns = ['RFV1','RFV2','RFV3']\nfor (rfv_code,rfv_desc) in zip(\n    rfv_codes['Code'].tolist(),rfv_codes['Description'].tolist()\n):\n    X_train = add_rfv_column(\n        X_train,\n        rfv_code,\n        rfv_desc,\n        rfv_columns\n    )\n    X_test = add_rfv_column(\n        X_test,\n        rfv_code,\n        rfv_desc,\n        rfv_columns \n    )\n    \n# Remove original RFV columns\nX_train.drop(rfv_columns, axis=1, inplace=True)\nX_test.drop(rfv_columns, axis=1, inplace=True)",
      "execution_count": 100,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "81a45abf7a2a51000c071dbb3c485b5b7046bba8"
      },
      "cell_type": "code",
      "source": "X_train.head(n=5)",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 101,
          "data": {
            "text/plain": "      VMONTH               ...                rfv_Direct_admission_to_hospital\n4232      06               ...                                               0\n20594     01               ...                                               0\n10153     10               ...                                               0\n15805     04               ...                                               0\n18066     09               ...                                               0\n\n[5 rows x 1264 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VMONTH</th>\n      <th>VDAYR</th>\n      <th>WAITTIME</th>\n      <th>AGE</th>\n      <th>AGER</th>\n      <th>RESIDNCE</th>\n      <th>SEX</th>\n      <th>ETHUN</th>\n      <th>RACEUN</th>\n      <th>ARREMS</th>\n      <th>NOPAY</th>\n      <th>PAYPRIV</th>\n      <th>PAYMCARE</th>\n      <th>PAYMCAID</th>\n      <th>PAYWKCMP</th>\n      <th>PAYSELF</th>\n      <th>PAYNOCHG</th>\n      <th>PAYOTH</th>\n      <th>PAYDK</th>\n      <th>TEMPF</th>\n      <th>PULSE</th>\n      <th>RESPR</th>\n      <th>BPSYS</th>\n      <th>BPDIAS</th>\n      <th>POPCT</th>\n      <th>ONO2</th>\n      <th>IMMEDR</th>\n      <th>PAINSCALE</th>\n      <th>SEEN72</th>\n      <th>EPISODE</th>\n      <th>INJURY</th>\n      <th>INJR1</th>\n      <th>INJR2</th>\n      <th>INJPOISAD</th>\n      <th>INJPOISADR1</th>\n      <th>INJPOISADR2</th>\n      <th>INTENT</th>\n      <th>INJDETR</th>\n      <th>INJDETR1</th>\n      <th>INJDETR2</th>\n      <th>...</th>\n      <th>rfv_Food_poisoning</th>\n      <th>rfv_Ingestion_inhalation_or_exposure_to_potentially_poisonous_products</th>\n      <th>rfv_Adverse_effect_of_medication</th>\n      <th>rfv_Adverse_effect_of_drug_abuse</th>\n      <th>rfv_Adverse_effect_of_alcohol</th>\n      <th>rfv_Alcohol_poisoning</th>\n      <th>rfv_Adverse_effects_of_environment</th>\n      <th>rfv_Adverse_effects_of_secondhand_smoke</th>\n      <th>rfv_Adverse_effects_of_terrorism_and_bioterrorism</th>\n      <th>rfv_Adverse_effects_other_and_unspecified</th>\n      <th>rfv_Complications_of_surgical_or_medical_procedures_and_treatments</th>\n      <th>rfv_For_other_findings_of_blood_tests</th>\n      <th>rfv_For_results_of_urine_tests</th>\n      <th>rfv_For_cytology_findings</th>\n      <th>rfv_For_radiological_findings</th>\n      <th>rfv_For_results_of_blood_glucose_tests</th>\n      <th>rfv_For_results_of_EKG_Holter_monitor_review_abnormal</th>\n      <th>rfv_For_results_of_skin_tests</th>\n      <th>rfv_For_results_of_cholesterol_and_triglyceride_tests</th>\n      <th>rfv_For_other_and_unspecified_test_results</th>\n      <th>rfv_For_results_of_test_for_human_immunodeficiency</th>\n      <th>rfv_Physical_examination_required_for_school_or_employment</th>\n      <th>rfv_Other_reason_for_visit_required_by_party_other_than_the_patient_or_the_health_care_provider</th>\n      <th>rfv_Physical_examination_required_for_employment</th>\n      <th>rfv_Executive_physical_examination</th>\n      <th>rfv_Physical_examination_required_for_school</th>\n      <th>rfv_Problems_complaints_NEC</th>\n      <th>rfv_Patient_unable_to_speak_English</th>\n      <th>rfv_Patient_or_patient's_spokesperson_refused_care</th>\n      <th>rfv_Physical_examination_for_extracurricular_activities</th>\n      <th>rfv_Entry_of_none_or_no_complaint</th>\n      <th>rfv_Insufficient_information</th>\n      <th>rfv_Driver's_license_examination_DOT_</th>\n      <th>rfv_Illegible_entry</th>\n      <th>rfv_Insurance_examination_</th>\n      <th>rfv_Disability_examination_</th>\n      <th>rfv_Workerâ€™s_comp_exam</th>\n      <th>rfv_Premarital_examination</th>\n      <th>rfv_Premarital_blood_test</th>\n      <th>rfv_Direct_admission_to_hospital</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4232</th>\n      <td>06</td>\n      <td>2</td>\n      <td>18.0</td>\n      <td>66</td>\n      <td>5</td>\n      <td>01</td>\n      <td>1</td>\n      <td>02</td>\n      <td>02</td>\n      <td>02</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>98.7</td>\n      <td>73.0</td>\n      <td>20.000000</td>\n      <td>118.0</td>\n      <td>61.0</td>\n      <td>100.0</td>\n      <td>02</td>\n      <td>03</td>\n      <td>4.776526</td>\n      <td>02</td>\n      <td>01</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>04</td>\n      <td>04</td>\n      <td>04</td>\n      <td>-9</td>\n      <td>05</td>\n      <td>05</td>\n      <td>05</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20594</th>\n      <td>01</td>\n      <td>5</td>\n      <td>30.0</td>\n      <td>28</td>\n      <td>3</td>\n      <td>01</td>\n      <td>2</td>\n      <td>01</td>\n      <td>-9</td>\n      <td>02</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>98.1</td>\n      <td>86.0</td>\n      <td>20.000000</td>\n      <td>148.0</td>\n      <td>85.0</td>\n      <td>98.0</td>\n      <td>02</td>\n      <td>03</td>\n      <td>10.000000</td>\n      <td>02</td>\n      <td>01</td>\n      <td>01</td>\n      <td>1</td>\n      <td>1</td>\n      <td>01</td>\n      <td>01</td>\n      <td>01</td>\n      <td>-9</td>\n      <td>-9</td>\n      <td>03</td>\n      <td>03</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10153</th>\n      <td>10</td>\n      <td>5</td>\n      <td>11.0</td>\n      <td>52</td>\n      <td>4</td>\n      <td>01</td>\n      <td>2</td>\n      <td>02</td>\n      <td>01</td>\n      <td>02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>98.7</td>\n      <td>98.0</td>\n      <td>28.000000</td>\n      <td>160.0</td>\n      <td>106.0</td>\n      <td>100.0</td>\n      <td>02</td>\n      <td>04</td>\n      <td>10.000000</td>\n      <td>01</td>\n      <td>02</td>\n      <td>01</td>\n      <td>1</td>\n      <td>1</td>\n      <td>01</td>\n      <td>01</td>\n      <td>01</td>\n      <td>-9</td>\n      <td>-9</td>\n      <td>03</td>\n      <td>03</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15805</th>\n      <td>04</td>\n      <td>3</td>\n      <td>139.0</td>\n      <td>26</td>\n      <td>3</td>\n      <td>01</td>\n      <td>1</td>\n      <td>02</td>\n      <td>01</td>\n      <td>02</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>98.4</td>\n      <td>75.0</td>\n      <td>19.568148</td>\n      <td>111.0</td>\n      <td>58.0</td>\n      <td>100.0</td>\n      <td>02</td>\n      <td>03</td>\n      <td>7.000000</td>\n      <td>02</td>\n      <td>01</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>04</td>\n      <td>04</td>\n      <td>04</td>\n      <td>-9</td>\n      <td>05</td>\n      <td>05</td>\n      <td>05</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18066</th>\n      <td>09</td>\n      <td>5</td>\n      <td>19.0</td>\n      <td>45</td>\n      <td>4</td>\n      <td>01</td>\n      <td>2</td>\n      <td>-9</td>\n      <td>01</td>\n      <td>02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>98.0</td>\n      <td>109.0</td>\n      <td>18.000000</td>\n      <td>199.0</td>\n      <td>111.0</td>\n      <td>94.0</td>\n      <td>02</td>\n      <td>-8</td>\n      <td>4.776526</td>\n      <td>02</td>\n      <td>01</td>\n      <td>00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>04</td>\n      <td>04</td>\n      <td>04</td>\n      <td>-9</td>\n      <td>05</td>\n      <td>05</td>\n      <td>05</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "865df7ca98a6024b1bb6b785c44268be63d8b126"
      },
      "cell_type": "markdown",
      "source": "### Injury codes"
    },
    {
      "metadata": {
        "_uuid": "b4c008289ddf45f644e400b38d1e581d36bd882b"
      },
      "cell_type": "markdown",
      "source": "Injury codes only apply if the patient has undergone either physical injury, poisoning, or adverse effects of medical treatment (including suicide attempts). Because the exact reason for injury may not be known until a full workup has been performed, and that workup usually occurs after a decision to admit has already been made. Therefore, we will remove the injury code variables."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf5851a77e241ab625e4f34f195e48c586f04c6d"
      },
      "cell_type": "code",
      "source": "inj_cols = [\n    'INJURY','INJR1','INJR2','INJPOISAD','INJPOISADR1',\n    'INJPOISADR2','INTENT','INJDETR','INJDETR1','INJDETR2',\n    'CAUSE1','CAUSE2','CAUSE3','CAUSE1R','CAUSE2R','CAUSE3R'\n]\n\nX_train.drop(inj_cols, axis=1, inplace=True)\nX_test.drop(inj_cols, axis=1, inplace=True)",
      "execution_count": 102,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "89e8beff2d203e5d5cbd4e213b6b9854f995028f"
      },
      "cell_type": "markdown",
      "source": "### Diagnostic codes\nFor the same reason as the injury codes, these variables will be removed."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74f49936c1dd445a53dca31681b120986343dc5e"
      },
      "cell_type": "code",
      "source": "diag_cols= [\n    'DIAG1','DIAG2','DIAG3',\n    'PRDIAG1','PRDIAG2','PRDIAG3',\n    'DIAG1R','DIAG2R','DIAG3R'\n]\n\nX_train.drop(diag_cols, axis=1, inplace=True)\nX_test.drop(diag_cols, axis=1, inplace=True)",
      "execution_count": 103,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "96f9a4c8863592337d3be696047d1b53da3d32d3"
      },
      "cell_type": "markdown",
      "source": "### Medical history"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "704eb2c2525a595f0c3583c6ad7f7f54ef055b68"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,'TOTCHRON'] = X_train.loc[:,'TOTCHRON'].apply(pd.to_numeric)\nX_test.loc[:,'TOTCHRON'] = X_test.loc[:,'TOTCHRON'].apply(pd.to_numeric)\n\nX_train = mean_impute_values(X_train,'TOTCHRON')\nX_test = mean_impute_values(X_test,'TOTCHRON')",
      "execution_count": 104,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a3ac9f4f336b69993e11edf16c90cdc450198d05"
      },
      "cell_type": "markdown",
      "source": "### Test"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "199ab7c79ed83dd9b1bc98ba67ad2a807ef1e17c"
      },
      "cell_type": "code",
      "source": "testing_cols = [\n    'ABG','BAC','BLOODCX','BNP','BUNCREAT',\n    'CARDENZ','CBC','DDIMER','ELECTROL','GLUCOSE',\n    'LACTATE','LFT','PTTINR','OTHERBLD','CARDMON',\n    'EKG','HIVTEST','FLUTEST','PREGTEST','TOXSCREN',\n    'URINE','WOUNDCX','URINECX','OTHRTEST','ANYIMAGE',\n    'XRAY','IVCONTRAST','CATSCAN','CTAB','CTCHEST',\n    'CTHEAD','CTOTHER','CTUNK','MRI','ULTRASND',\n    'OTHIMAGE','TOTDIAG','DIAGSCRN'\n]\n\nX_train.drop(testing_cols, axis=1, inplace=True)\nX_test.drop(testing_cols, axis=1, inplace=True)",
      "execution_count": 105,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "12fa2f064c175af442c3f6c03461977bd2900549"
      },
      "cell_type": "markdown",
      "source": "### Procedures\nWe omit procedures because, similar to the tests, they often occur post-prediction time."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2233255b79c17a4ffddabcd23f1db0a19e5e5238"
      },
      "cell_type": "code",
      "source": "proc_cols = [\n    'PROC','BPAP','BLADCATH','CASTSPLINT','CENTLINE',\n    'CPR','ENDOINT','INCDRAIN','IVFLUIDS','LUMBAR',\n    'NEBUTHER','PELVIC','SKINADH','SUTURE','OTHPROC',\n    'TOTPROC'\n]\n\nX_train.drop(proc_cols, axis=1, inplace=True)\nX_test.drop(proc_cols, axis=1, inplace=True)",
      "execution_count": 106,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "68530a811af252a0d77d1062177755d509d6c6c8"
      },
      "cell_type": "markdown",
      "source": "### Medication codes"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4488d3d9d49ebc2c9cc632f46d0c718815776166"
      },
      "cell_type": "code",
      "source": "med_cols = [\n    'MED1','MED2','MED3','MED4','MED5',\n    'MED6','MED7','MED8','MED9','MED10',\n    'MED11','MED12','GPMED1','GPMED2','GPMED3',\n    'GPMED4','GPMED5','GPMED6','GPMED7','GPMED8',\n    'GPMED9','GPMED10','GPMED11','GPMED12','NUMGIV',\n    'NUMDIS','NUMMED',\n]\n\nX_train.drop(med_cols, axis=1, inplace=True)\nX_test.drop(med_cols, axis=1, inplace=True)",
      "execution_count": 107,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "15473faa7f88085a934cb4fdd0622ab5865e2727"
      },
      "cell_type": "markdown",
      "source": "### Provider information"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e39da49652879d3576cb7b444e0a15a8eb714bdc"
      },
      "cell_type": "code",
      "source": "prov_cols = [\n    'NOPROVID','ATTPHYS','RESINT','CONSULT','RNLPN',\n    'NURSEPR','PHYSASST','EMT','MHPROV','OTHPROV'\n]\n\nX_train.drop(prov_cols, axis=1, inplace=True)\nX_test.drop(prov_cols, axis=1, inplace=True)",
      "execution_count": 108,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "23c4944737f59c4567042991d0e4df7ecad2cc1b"
      },
      "cell_type": "markdown",
      "source": "### Disposition information"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07e69ec8d6589cf6a573b5a56556502f13da60da"
      },
      "cell_type": "code",
      "source": "disp_cols = [\n    'NODISP','NOFU','RETRNED','RETREFFU','LEFTBTRI',\n    'LEFTAMA','DOA','DIEDED','TRANNH','OTHDISP',\n    'ADMIT','ADMTPHYS','BOARDED','LOS','HDDIAG1',\n    'HDDIAG2','HDDIAG3','HDDIAG1R','HDDIAG2R','HDDIAG3R',\n    'HDSTAT','ADISP','OBSSTAY','STAY24'\n]",
      "execution_count": 109,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dff2a9804ee48b8a18c8fd8fd1c16cb4839e87a3"
      },
      "cell_type": "code",
      "source": "X_train.drop(disp_cols, axis=1, inplace=True)\nX_test.drop(disp_cols, axis=1, inplace=True)",
      "execution_count": 110,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2a2d2515da97ea10b85ae5f4b5a3745ccfb99f34"
      },
      "cell_type": "markdown",
      "source": "### Pre-Imputed columns"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3143903fab2248fd5ae79fae7cd8538e9eff0d0a"
      },
      "cell_type": "code",
      "source": "imp_cols = [\n    'AGEFL','BDATEFL','SEXFL','ETHNICFL','RACERFL'\n]\n\nX_train.drop(imp_cols, axis=1, inplace=True)\nX_test.drop(imp_cols, axis=1, inplace=True)",
      "execution_count": 111,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ccd0180ed16932207b12bbc909fd1151fc12c885"
      },
      "cell_type": "markdown",
      "source": "### Identifying variables"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30963e91209a6ee5e9c0db95285a4021d1ef9df0"
      },
      "cell_type": "code",
      "source": "id_cols = [\n    'HOSPCODE','PATCODE'\n]\n\nX_train.drop(id_cols, axis=1, inplace=True)\nX_test.drop(id_cols, axis=1, inplace=True)",
      "execution_count": 112,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e7df181220b1be822c4e721e390aa28e24fdc3f4"
      },
      "cell_type": "markdown",
      "source": "### Electronic medical record status columns"
    },
    {
      "metadata": {
        "_uuid": "4921b76b3fc004400aaa4b01114f6939773ce6ed"
      },
      "cell_type": "markdown",
      "source": "We omit these columns since they are valued on a per-hospital basis rather than a per-encounter basis."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "32014be22e6949ebda0f26c6a1d5d3630bdfaf18"
      },
      "cell_type": "code",
      "source": "emr_cols = [\n    'EBILLANYE','EMRED','HHSMUE','EHRINSE','EDEMOGE',\n    'EDEMOGER','EPROLSTE','EPROLSTER','EVITALE','EVITALER',\n    'ESMOKEE','ESMOKEER','EPNOTESE','EPNOTESER','EMEDALGE',\n    'EMEDALGER','ECPOEE','ECPOEER','ESCRIPE','ESCRIPER',\n    'EWARNE','EWARNER','EREMINDE','EREMINDER','ECTOEE',\n    'ECTOEER','EORDERE','EORDERER','ERESULTE','ERESULTER',\n    'EGRAPHE','EGRAPHER','EIMGRESE','EIMGRESER','EPTEDUE',\n    'EPTEDUER','ECQME','ECQMER','EGENLISTE','EGENLISTER',\n    'EIMMREGE','EIMMREGER','ESUME','ESUMER','EMSGE',\n    'EMSGER','EHLTHINFOE','EHLTHINFOER','EPTRECE','EPTRECER',\n    'EMEDIDE','EMEDIDER','ESHAREE','ESHAREEHRE','ESHAREWEBE',\n    'ESHAREOTHE','ESHAREUNKE','ESHAREREFE','LABRESE1','LABRESE2',\n    'LABRESE3','LABRESE4','LABRESUNKE','LABRESREFE','IMAGREPE1',\n    'IMAGREPE2','IMAGREPE3','IMAGREPE4','IMAGREPUNKE','IMAGREPREFE',\n    'PTPROBE1','PTPROBE2','PTPROBE3','PTPROBE4','PTPROBUNKE',\n    'PTPROBREFE','MEDLISTE1','MEDLISTE2','MEDLISTE3','MEDLISTE4',\n    'MEDLISTUNKE','MEDLISTREFE','ALGLISTE1','ALGLISTE2','ALGLISTE3',\n    'ALGLISTE4','ALGLISTUNKE','ALGLISTREFE','EDPRIM','EDINFO',\n    'MUINC','MUYEAR'\n]\n\nX_train.drop(emr_cols, axis=1, inplace=True)\nX_test.drop(emr_cols, axis=1, inplace=True)",
      "execution_count": 113,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "446a17da02781df810bc5bc28803012f27cd4edd"
      },
      "cell_type": "markdown",
      "source": "### Detailed medication information"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e2c8a6492ea41de04668ad95e8ab108191396bb5"
      },
      "cell_type": "code",
      "source": "drug_id_cols = [\n    'DRUGID1','DRUGID2','DRUGID3','DRUGID4','DRUGID5',\n    'DRUGID6','DRUGID7','DRUGID8','DRUGID9','DRUGID10',\n    'DRUGID11','DRUGID12'\n]\n\ndrug_lev1_cols = [\n    'RX1V1C1','RX1V1C2','RX1V1C3','RX1V1C4',\n    'RX2V1C1','RX2V1C2','RX2V1C3','RX2V1C4',\n    'RX3V1C1','RX3V1C2','RX3V1C3','RX3V1C4',\n    'RX4V1C1','RX4V1C2','RX4V1C3','RX4V1C4',\n    'RX5V1C1','RX5V1C2','RX5V1C3','RX5V1C4',\n    'RX6V1C1','RX6V1C2','RX6V1C3','RX6V1C4',\n    'RX7V1C1','RX7V1C2','RX7V1C3','RX7V1C4',\n    'RX8V1C1','RX8V1C2','RX8V1C3','RX8V1C4',\n    'RX9V1C1','RX9V1C2','RX9V1C3','RX9V1C4',\n    'RX10V1C1','RX10V1C2','RX10V1C3','RX10V1C4',\n    'RX11V1C1','RX11V1C2','RX11V1C3','RX11V1C4',\n    'RX12V1C1','RX12V1C2','RX12V1C3','RX12V1C4'\n]\n\ndrug_lev2_cols = [\n    'RX1V2C1','RX1V2C2','RX1V2C3','RX1V2C4',\n    'RX2V2C1','RX2V2C2','RX2V2C3','RX2V2C4',\n    'RX3V2C1','RX3V2C2','RX3V2C3','RX3V2C4',\n    'RX4V2C1','RX4V2C2','RX4V2C3','RX4V2C4',\n    'RX5V2C1','RX5V2C2','RX5V2C3','RX5V2C4',\n    'RX6V2C1','RX6V2C2','RX6V2C3','RX6V2C4',\n    'RX7V2C1','RX7V2C2','RX7V2C3','RX7V2C4',\n    'RX8V2C1','RX8V2C2','RX8V2C3','RX8V2C4',\n    'RX9V2C1','RX9V2C2','RX9V2C3','RX9V2C4',\n    'RX10V2C1','RX10V2C2','RX10V2C3','RX10V2C4',\n    'RX11V2C1','RX11V2C2','RX11V2C3','RX11V2C4',\n    'RX12V2C1','RX12V2C2','RX12V2C3','RX12V2C4'\n]\ndrug_lev3_cols = [\n    'RX1V3C1','RX1V3C2','RX1V3C3','RX1V3C4',\n    'RX2V3C1','RX2V3C2','RX2V3C3','RX2V3C4',\n    'RX3V3C1','RX3V3C2','RX3V3C3','RX3V3C4',\n    'RX4V3C1','RX4V3C2','RX4V3C3','RX4V3C4',\n    'RX5V3C1','RX5V3C2','RX5V3C3','RX5V3C4',\n    'RX6V3C1','RX6V3C2','RX6V3C3','RX6V3C4',\n    'RX7V3C1','RX7V3C2','RX7V3C3','RX7V3C4',\n    'RX8V3C1','RX8V3C2','RX8V3C3','RX8V3C4',\n    'RX9V3C1','RX9V3C2','RX9V3C3','RX9V3C4',\n    'RX10V3C1','RX10V3C2','RX10V3C3','RX10V3C4',\n    'RX11V3C1','RX11V3C2','RX11V3C3','RX11V3C4',\n    'RX12V3C1','RX12V3C2','RX12V3C3','RX12V3C4'\n]\n\naddl_drug_cols = [\n    'PRESCR1','CONTSUB1','COMSTAT1','RX1CAT1','RX1CAT2',\n    'RX1CAT3','RX1CAT4','PRESCR2','CONTSUB2','COMSTAT2',\n    'RX2CAT1','RX2CAT2','RX2CAT3','RX2CAT4','PRESCR3','CONTSUB3',\n    'COMSTAT3','RX3CAT1','RX3CAT2','RX3CAT3','RX3CAT4','PRESCR4',\n    'CONTSUB4','COMSTAT4','RX4CAT1','RX4CAT2','RX4CAT3',\n    'RX4CAT4','PRESCR5','CONTSUB5','COMSTAT5','RX5CAT1',\n    'RX5CAT2','RX5CAT3','RX5CAT4','PRESCR6','CONTSUB6',\n    'COMSTAT6','RX6CAT1','RX6CAT2','RX6CAT3','RX6CAT4','PRESCR7',\n    'CONTSUB7','COMSTAT7','RX7CAT1','RX7CAT2','RX7CAT3',\n    'RX7CAT4','PRESCR8','CONTSUB8','COMSTAT8','RX8CAT1',\n    'RX8CAT2','RX8CAT3','RX8CAT4','PRESCR9','CONTSUB9',\n    'COMSTAT9','RX9CAT1','RX9CAT2','RX9CAT3','RX9CAT4',\n    'PRESCR10','CONTSUB10','COMSTAT10','RX10CAT1','RX10CAT2',\n    'RX10CAT3','RX10CAT4','PRESCR11','CONTSUB11','COMSTAT11',\n    'RX11CAT1','RX11CAT2','RX11CAT3','RX11CAT4','PRESCR12',\n    'CONTSUB12','COMSTAT12','RX12CAT1','RX12CAT2','RX12CAT3',\n    'RX12CAT4'\n]\n\nX_train.drop(drug_id_cols, axis=1, inplace=True)\nX_train.drop(drug_lev1_cols, axis=1, inplace=True)\nX_train.drop(drug_lev2_cols, axis=1, inplace=True)\nX_train.drop(drug_lev3_cols, axis=1, inplace=True)\nX_train.drop(addl_drug_cols, axis=1, inplace=True)\n\nX_test.drop(drug_id_cols, axis=1, inplace=True)\nX_test.drop(drug_lev1_cols, axis=1, inplace=True)\nX_test.drop(drug_lev2_cols, axis=1, inplace=True)\nX_test.drop(drug_lev3_cols, axis=1, inplace=True)\nX_test.drop(addl_drug_cols, axis=1, inplace=True)",
      "execution_count": 114,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "94e771c027f055f8996e27051a6e35cd0df17b9e"
      },
      "cell_type": "markdown",
      "source": "### Miscellaneous information"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad39da4d3e5087bb9d0d8e654b638b75c992d371"
      },
      "cell_type": "code",
      "source": "design_cols = ['CSTRATM','CPSUM','PATWT','EDWT']\n\nX_train.drop(design_cols, axis=1, inplace=True)\nX_test.drop(design_cols, axis=1, inplace=True)",
      "execution_count": 115,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4b3c422f61e945f23278b0563a74507069c0e1b2"
      },
      "cell_type": "markdown",
      "source": "### One-hot encoding"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41fed64f441a0357a804ecdbf68e19b438480a2a"
      },
      "cell_type": "code",
      "source": "categ_cols = df_helper.loc[\n    df_helper['variable_type'] == 'CATEGORICAL', 'column_name'\n]\n\none_hot_cols = list(set(categ_cols) & set(X_train.columns))\n\nX_train = pd.get_dummies(X_train, columns=one_hot_cols)",
      "execution_count": 116,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4511252118f0eb6dbf91b9b8da0b451004129ddd"
      },
      "cell_type": "code",
      "source": "X_test = pd.get_dummies(X_test, columns=one_hot_cols)",
      "execution_count": 117,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a05c91680c186283e88ccb7410aa53919c9754ed"
      },
      "cell_type": "markdown",
      "source": "### Numeric conversion"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "989abebb4a0e0f377d6e0cc7955458e4e05c77be"
      },
      "cell_type": "code",
      "source": "X_train.loc[:,X_train.columns] = X_train.loc[:,X_train.columns].apply(pd.to_numeric)\nX_test.loc[:,X_test.columns] = X_test.loc[:,X_test.columns].apply(pd.to_numeric)",
      "execution_count": 118,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e846d45c4315fb148cddaa3f9e1607e27e216a43"
      },
      "cell_type": "markdown",
      "source": "### NumPy array conversion"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e90b56b1b8590769da51e1f62c31d5f1a57d1f20"
      },
      "cell_type": "code",
      "source": "X_train_cols = X_train.columns\nX_test_cols = X_test.columns",
      "execution_count": 119,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5affd051e464b3d980dbc4e56aeab6a0f73a7be"
      },
      "cell_type": "code",
      "source": "X_train = X_train.values\nX_test = X_test.values",
      "execution_count": 120,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "70c2d97029bcfe66fb2206a6da7925a08c63c401"
      },
      "cell_type": "markdown",
      "source": "# Building the models"
    },
    {
      "metadata": {
        "_uuid": "9b67cbc31ada913484d39e16756d08925fc02bca"
      },
      "cell_type": "markdown",
      "source": "## Logistic regression"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a002eaf4ca7f9f05332ddf60f420667eb95dec62"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\n\nclfs = [LogisticRegression()]\n\nfor clf in clfs:\n    clf.fit(X_train, y_train)\n    print(type(clf))\n    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n    \n    coefs = {\n        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n        'coef': [clf.coef_[0,i] for i in range(len(X_train_cols))]\n    }\n    df_coefs = pd.DataFrame(coefs)\n    print(df_coefs.sort_values('coef', axis=0, ascending=False))",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "<class 'sklearn.linear_model.logistic.LogisticRegression'>\nTraining accuracy: 0.8860187278010978\nValidation accuracy: 0.886682808716707\n                                                column      coef\n346                     rfv_Symptoms_of_onset_of_labor  2.066923\n108  rfv_Other_symptoms_or_problems_relating_to_psy...  1.388934\n520  rfv_General_psychiatric_or_psychological_exami...  1.235171\n688                                rfv_Suicide_attempt  1.031974\n795                                          IMMEDR_01  0.899332\n201         rfv_Labored_or_difficult_breathing_dyspnea  0.883669\n88                                     rfv_Depression_  0.880418\n796                                          IMMEDR_02  0.820472\n95                     rfv_Delusions_or_hallucinations  0.808396\n696                   rfv_Adverse_effect_of_drug_abuse  0.788406\n55                             rfv_Chest_pain_soreness  0.782589\n607                         rfv_Medical_Counseling_NOS  0.773309\n42                                rfv_General_weakness  0.772377\n712         rfv_For_other_and_unspecified_test_results  0.762062\n470                        rfv_Cerebrovascular_disease  0.760259\n500  rfv_Diagnosed_complications_of_pregnancy_and_p...  0.717217\n197                            rfv_Shortness_of_breath  0.696758\n253             rfv_Lower_abdominal_pain_cramps_spasms  0.687594\n89                                rfv_Hostile_behavior  0.612128\n274                          rfv_Blood_in_stool_melena  0.607879\n262                                       rfv_Vomiting  0.603609\n807                                          INCSHX_-8  0.579838\n257             rfv_Upper_abdominal_pain_cramps_spasms  0.565714\n251               rfv_Abdominal_pain_cramps_spasms_NOS  0.558172\n126                            rfv_Weakness_neurologic  0.547310\n762                                          EDPTOR_01  0.526433\n689                           rfv_Overdose_intentional  0.520913\n130  rfv_Other_symptoms_referable_to_the_nervous_sy...  0.517154\n442                                         rfv_Anemia  0.513453\n46                                           rfv_Edema  0.509764\n..                                                 ...       ...\n247   rfv_Stomach_and_abdominal_pain_cramps_and_spasms -0.370668\n679                                 rfv_Cardiac_arrest -0.374436\n811                                          SEEN72_-8 -0.392636\n834                                         BEDDATA_06 -0.397994\n872                                          ARREMS_02 -0.401563\n668                             rfv_Animal_snake_human -0.404164\n27                                                 DVT -0.408160\n79                                     rfv_Allergy_NOS -0.408452\n831                                         BEDDATA_03 -0.411840\n665                                         rfv_Insect -0.413542\n569         rfv_Medication_other_and_unspecified_kinds -0.414177\n760                                          EDPTOR_-8 -0.440686\n816                                            ONO2_-9 -0.442658\n806                                       OBSPHYSUN_01 -0.454451\n643                                  rfv_Foot_and_toes -0.454578\n753                                        RESIDNCE_02 -0.467236\n207                        rfv_Nosebleed_epistaxis_NEC -0.486319\n625                               rfv_Hand_and_fingers -0.519792\n84                         rfv_Anxiety_and_nervousness -0.527548\n280                                  rfv_Constipation_ -0.556708\n783                                          OBSSEP_02 -0.578852\n571                            rfv_Postoperative_visit -0.652204\n235                                      rfv_Toothache -0.674104\n604                      rfv_Suture__insertion_removal -0.715170\n217                                       rfv_Soreness -0.738374\n188                                  rfv_Earache_pain_ -0.771876\n798                                          IMMEDR_04 -0.832928\n371                                      rfv_Skin_rash -0.877674\n799                                          IMMEDR_05 -0.998671\n30                                            LEFTATRI -1.142985\n\n[941 rows x 2 columns]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "76dc63a2fe9b22c0efb0ef537654b810ca343449"
      },
      "cell_type": "markdown",
      "source": "## Random forest"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02f55da05d41762cc5edcb020c6baada5e004c35"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nclfs_rf = [RandomForestClassifier(n_estimators=100)]\n\nfor clf in clfs_rf:\n    clf.fit(X_train, y_train)\n    print(type(clf))\n    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n    \n    imps = {\n        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n        'imp': [clf.feature_importances_[i] for i in range(len(X_train_cols))]\n    }\n    df_imps = pd.DataFrame(imps)\n    print(df_imps.sort_values('imp', axis=0, ascending=False))",
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  \n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\nTraining accuracy: 1.0\nValidation accuracy: 0.8828087167070218\n                                                column       imp\n1                                                  AGE  0.036652\n13                                               PULSE  0.028601\n15                                               BPSYS  0.027059\n16                                              BPDIAS  0.026471\n12                                               TEMPF  0.024818\n0                                             WAITTIME  0.024795\n17                                               POPCT  0.021069\n14                                               RESPR  0.020226\n29                                            TOTCHRON  0.017520\n18                                           PAINSCALE  0.016664\n872                                          ARREMS_02  0.014394\n871                                          ARREMS_01  0.014194\n796                                          IMMEDR_02  0.014148\n922                                             AGER_6  0.012860\n839                                          NOCHRON_0  0.011142\n5                                             PAYMCARE  0.010409\n817                                            ONO2_01  0.009022\n108  rfv_Other_symptoms_or_problems_relating_to_psy...  0.008677\n197                            rfv_Shortness_of_breath  0.008507\n31                                             SURGDAY  0.007874\n840                                          NOCHRON_1  0.007683\n798                                          IMMEDR_04  0.007393\n55                             rfv_Chest_pain_soreness  0.007193\n2                                                  SEX  0.006562\n4                                              PAYPRIV  0.006116\n34                                               NIGHT  0.006095\n797                                          IMMEDR_03  0.005618\n920                                             AGER_4  0.005604\n23                                                 CHF  0.005454\n6                                             PAYMCAID  0.005342\n..                                                 ...       ...\n319                                     rfv_Infrequent  0.000000\n321                rfv_Irregularity_of_menstrual_flow_  0.000000\n701  rfv_Adverse_effects_of_terrorism_and_bioterrorism  0.000000\n459                               rfv_Refractive_error  0.000000\n460                                       rfv_Cataract  0.000000\n461                                       rfv_Glaucoma  0.000000\n324                    rfv_Scanty_flow_oligomenorrhea_  0.000000\n465  rfv_Rheumatic_fever_and_chronic_rheumatic_hear...  0.000000\n615                               rfv_Marital_problems  0.000000\n613                               rfv_Economic_problem  0.000000\n452                     rfv_Attention_deficit_disorder  0.000000\n315     rfv_Other_symptoms_of_male_reproductive_system  0.000000\n350                     rfv_Postcoital_bleeding_female  0.000000\n447           rfv_Personality_and_character_disorders_  0.000000\n700            rfv_Adverse_effects_of_secondhand_smoke  0.000000\n698                              rfv_Alcohol_poisoning  0.000000\n301                                           rfv_Mass  0.000000\n302                        rfv_Symptoms_of_the_kidneys  0.000000\n436                   rfv_Neoplasm_of_uncertain_nature  0.000000\n693                                 rfv_Food_poisoning  0.000000\n692                        rfv_Unintentional_poisoning  0.000000\n307                      rfv_Lumps_bumps_growths_warts  0.000000\n683                                       rfv_Drowning  0.000000\n682                                    rfv_Elder_abuse  0.000000\n681                               rfv_Battered_spouse_  0.000000\n675                            rfv_Dead_on_arrival_DOA  0.000000\n352  rfv_Other_symptoms_referable_to_the_female_rep...  0.000000\n313                      rfv_Growths_warts_lumps_bumps  0.000000\n314                              rfv_Itching_jock_itch  0.000000\n710                      rfv_For_results_of_skin_tests  0.000000\n\n[941 rows x 2 columns]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "11750d4ac7e2fcf9030015b2a54f7e2c667bb3ff"
      },
      "cell_type": "markdown",
      "source": "## Neural network"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ed16fbf288190e9d4b2c77aaef29024f21ff61a"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier \n\n# Scale data\nscaler = StandardScaler() \nscaler.fit(X_train) \nX_train_Tx = scaler.transform(X_train) \nX_test_Tx = scaler.transform(X_test) \n\n# Fit models that require scaling (e.g. neural networks)\nhl_sizes = [150,100,80,60,40,20]\nnn_clfs = [MLPClassifier(hidden_layer_sizes=(size,), random_state=2345, verbose=True) for size in hl_sizes]\n\nfor num, nn_clf in enumerate(nn_clfs):\n    print(str(hl_sizes[num]) + '-unit network:')\n    nn_clf.fit(X_train_Tx, y_train)\n    print('Training accuracy: ' + str(nn_clf.score(X_train_Tx, y_train)))\n    print('Validation accuracy: ' + str(nn_clf.score(X_test_Tx, y_test)))",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": "150-unit network:\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Iteration 1, loss = 0.46042747\nIteration 2, loss = 0.26762774\nIteration 3, loss = 0.23099945\nIteration 4, loss = 0.20990494\nIteration 5, loss = 0.19234417\nIteration 6, loss = 0.17454482\nIteration 7, loss = 0.15777271\nIteration 8, loss = 0.14261363\nIteration 9, loss = 0.12760340\nIteration 10, loss = 0.11404992\nIteration 11, loss = 0.10026963\nIteration 12, loss = 0.08864339\nIteration 13, loss = 0.07872664\nIteration 14, loss = 0.06766217\nIteration 15, loss = 0.06049338\nIteration 16, loss = 0.05281394\nIteration 17, loss = 0.04664527\nIteration 18, loss = 0.04040355\nIteration 19, loss = 0.03564911\nIteration 20, loss = 0.03147428\nIteration 21, loss = 0.02752492\nIteration 22, loss = 0.02445311\nIteration 23, loss = 0.02191182\nIteration 24, loss = 0.01964949\nIteration 25, loss = 0.01792721\nIteration 26, loss = 0.01644273\nIteration 27, loss = 0.01412957\nIteration 28, loss = 0.01222390\nIteration 29, loss = 0.01197503\nIteration 30, loss = 0.01027081\nIteration 31, loss = 0.00964919\nIteration 32, loss = 0.00816741\nIteration 33, loss = 0.00848181\nIteration 34, loss = 0.00775565\nIteration 35, loss = 0.00671114\nIteration 36, loss = 0.00643923\nIteration 37, loss = 0.00713251\nIteration 38, loss = 0.00776674\nIteration 39, loss = 0.00734837\nIteration 40, loss = 0.00589715\nIteration 41, loss = 0.00436986\nIteration 42, loss = 0.00478342\nIteration 43, loss = 0.00347119\nIteration 44, loss = 0.00311100\nIteration 45, loss = 0.00397898\nIteration 46, loss = 0.00347339\nIteration 47, loss = 0.00456574\nIteration 48, loss = 0.00449269\nIteration 49, loss = 0.00471075\nIteration 50, loss = 0.00402545\nIteration 51, loss = 0.00368014\nIteration 52, loss = 0.00294878\nIteration 53, loss = 0.00275852\nIteration 54, loss = 0.00246846\nIteration 55, loss = 0.00227912\nIteration 56, loss = 0.00375872\nIteration 57, loss = 0.00244039\nIteration 58, loss = 0.00271334\nIteration 59, loss = 0.02319259\nIteration 60, loss = 0.10750447\nIteration 61, loss = 0.12110838\nIteration 62, loss = 0.04722503\nIteration 63, loss = 0.01223036\nIteration 64, loss = 0.00557866\nIteration 65, loss = 0.00340293\nIteration 66, loss = 0.00317782\nTraining loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\nTraining accuracy: 0.9998923689592079\nValidation accuracy: 0.8857142857142857\n100-unit network:\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Iteration 1, loss = 0.36246986\nIteration 2, loss = 0.25986193\nIteration 3, loss = 0.23167331\nIteration 4, loss = 0.20980379\nIteration 5, loss = 0.19225833\nIteration 6, loss = 0.17533651\nIteration 7, loss = 0.16078798\nIteration 8, loss = 0.14319748\nIteration 9, loss = 0.12926094\nIteration 10, loss = 0.11454745\nIteration 11, loss = 0.10248543\nIteration 12, loss = 0.09084019\nIteration 13, loss = 0.08104346\nIteration 14, loss = 0.07228109\nIteration 15, loss = 0.06443965\nIteration 16, loss = 0.05622794\nIteration 17, loss = 0.05085809\nIteration 18, loss = 0.04518165\nIteration 19, loss = 0.03955685\nIteration 20, loss = 0.03703979\nIteration 21, loss = 0.03160814\nIteration 22, loss = 0.02916788\nIteration 23, loss = 0.02514193\nIteration 24, loss = 0.02260722\nIteration 25, loss = 0.02058863\nIteration 26, loss = 0.01810946\nIteration 27, loss = 0.01592094\nIteration 28, loss = 0.01407315\nIteration 29, loss = 0.01374555\nIteration 30, loss = 0.01317764\nIteration 31, loss = 0.01174809\nIteration 32, loss = 0.01045638\nIteration 33, loss = 0.01010027\nIteration 34, loss = 0.00922715\nIteration 35, loss = 0.00910640\nIteration 36, loss = 0.00752953\nIteration 37, loss = 0.00874199\nIteration 38, loss = 0.00719137\nIteration 39, loss = 0.00674455\nIteration 40, loss = 0.00731735\nIteration 41, loss = 0.00728049\nIteration 42, loss = 0.00536227\nIteration 43, loss = 0.00515504\nIteration 44, loss = 0.00727636\nIteration 45, loss = 0.00924246\nIteration 46, loss = 0.01396998\nIteration 47, loss = 0.01854450\nIteration 48, loss = 0.03282670\nIteration 49, loss = 0.03254385\nIteration 50, loss = 0.02395450\nIteration 51, loss = 0.02087012\nIteration 52, loss = 0.00967201\nIteration 53, loss = 0.00448207\nIteration 54, loss = 0.00318456\nIteration 55, loss = 0.00296629\nIteration 56, loss = 0.00309391\nIteration 57, loss = 0.00213307\nIteration 58, loss = 0.00263768\nIteration 59, loss = 0.00224870\nIteration 60, loss = 0.00221940\nIteration 61, loss = 0.00256123\nIteration 62, loss = 0.00253847\nIteration 63, loss = 0.00219194\nIteration 64, loss = 0.00239965\nIteration 65, loss = 0.00240323\nIteration 66, loss = 0.00612026\nIteration 67, loss = 0.00312800\nIteration 68, loss = 0.00282715\nTraining loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\nTraining accuracy: 0.9997309223980196\nValidation accuracy: 0.8789346246973365\n80-unit network:\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Iteration 1, loss = 0.35454070\nIteration 2, loss = 0.26225834\nIteration 3, loss = 0.23671209\nIteration 4, loss = 0.21851784\nIteration 5, loss = 0.20176831\nIteration 6, loss = 0.18600299\nIteration 7, loss = 0.17039497\nIteration 8, loss = 0.15523305\nIteration 9, loss = 0.14114271\nIteration 10, loss = 0.12678225\nIteration 11, loss = 0.11476329\nIteration 12, loss = 0.10208249\nIteration 13, loss = 0.09205445\nIteration 14, loss = 0.08243933\nIteration 15, loss = 0.07208936\nIteration 16, loss = 0.06474464\nIteration 17, loss = 0.05889930\nIteration 18, loss = 0.05399492\nIteration 19, loss = 0.04716947\nIteration 20, loss = 0.04413791\nIteration 21, loss = 0.03860912\nIteration 22, loss = 0.03468525\nIteration 23, loss = 0.03149394\nIteration 24, loss = 0.02844319\nIteration 25, loss = 0.02542893\nIteration 26, loss = 0.02332205\nIteration 27, loss = 0.02125126\nIteration 28, loss = 0.01900169\nIteration 29, loss = 0.01834657\nIteration 30, loss = 0.01587931\nIteration 31, loss = 0.01431643\nIteration 32, loss = 0.01359381\nIteration 33, loss = 0.01295109\nIteration 34, loss = 0.01162283\nIteration 35, loss = 0.01164475\nIteration 36, loss = 0.01094481\nIteration 37, loss = 0.00949504\nIteration 38, loss = 0.00869908\nIteration 39, loss = 0.00784198\nIteration 40, loss = 0.00771668\nIteration 41, loss = 0.00768119\nIteration 42, loss = 0.00827529\nIteration 43, loss = 0.00643077\nIteration 44, loss = 0.00591885\nIteration 45, loss = 0.00642158\nIteration 46, loss = 0.00530901\nIteration 47, loss = 0.00637992\nIteration 48, loss = 0.00540144\nIteration 49, loss = 0.00460224\nIteration 50, loss = 0.00431330\nIteration 51, loss = 0.00470202\nIteration 52, loss = 0.00406635\nIteration 53, loss = 0.00521328\nIteration 54, loss = 0.00474590\nIteration 55, loss = 0.00464474\nIteration 56, loss = 0.00323811\nIteration 57, loss = 0.00337889\nIteration 58, loss = 0.00293959\nIteration 59, loss = 0.00270071\nIteration 60, loss = 0.00239151\nIteration 61, loss = 0.00232680\nIteration 62, loss = 0.00283000\nIteration 63, loss = 0.00470816\nIteration 64, loss = 0.00426042\nIteration 65, loss = 0.01900725\nIteration 66, loss = 0.06538718\nIteration 67, loss = 0.07168983\nIteration 68, loss = 0.03256886\nIteration 69, loss = 0.01364987\nIteration 70, loss = 0.00521201\nIteration 71, loss = 0.00315521\nTraining loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\nTraining accuracy: 0.9998385534388118\nValidation accuracy: 0.8774818401937046\n60-unit network:\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Iteration 1, loss = 0.43357381\nIteration 2, loss = 0.27888069\nIteration 3, loss = 0.24739004\nIteration 4, loss = 0.22782233\nIteration 5, loss = 0.21412121\nIteration 6, loss = 0.20152233\nIteration 7, loss = 0.18912834\nIteration 8, loss = 0.17768024\nIteration 9, loss = 0.16643064\nIteration 10, loss = 0.15500260\nIteration 11, loss = 0.14202183\nIteration 12, loss = 0.13168001\nIteration 13, loss = 0.12215761\nIteration 14, loss = 0.11166814\nIteration 15, loss = 0.10143313\nIteration 16, loss = 0.09344256\nIteration 17, loss = 0.08525069\nIteration 18, loss = 0.07834549\nIteration 19, loss = 0.07207005\nIteration 20, loss = 0.06564179\nIteration 21, loss = 0.06120169\nIteration 22, loss = 0.05591804\nIteration 23, loss = 0.05146194\nIteration 24, loss = 0.04729026\nIteration 25, loss = 0.04346369\nIteration 26, loss = 0.04028081\nIteration 27, loss = 0.03733748\nIteration 28, loss = 0.03463643\nIteration 29, loss = 0.03126852\nIteration 30, loss = 0.02920701\nIteration 31, loss = 0.02780134\nIteration 32, loss = 0.02537660\nIteration 33, loss = 0.02321841\nIteration 34, loss = 0.02124148\nIteration 35, loss = 0.01950178\nIteration 36, loss = 0.01836351\nIteration 37, loss = 0.01763937\nIteration 38, loss = 0.01708266\nIteration 39, loss = 0.01620634\nIteration 40, loss = 0.01567419\nIteration 41, loss = 0.01342846\nIteration 42, loss = 0.01247673\nIteration 43, loss = 0.01088337\nIteration 44, loss = 0.01029677\nIteration 45, loss = 0.00993637\nIteration 46, loss = 0.00983135\nIteration 47, loss = 0.00915182\nIteration 48, loss = 0.00822481\nIteration 49, loss = 0.00925170\nIteration 50, loss = 0.00844922\nIteration 51, loss = 0.00843065\nIteration 52, loss = 0.00726845\nIteration 53, loss = 0.00640614\nIteration 54, loss = 0.00879360\nIteration 55, loss = 0.00804193\nIteration 56, loss = 0.00735653\nIteration 57, loss = 0.00874466\nIteration 58, loss = 0.00633616\nIteration 59, loss = 0.00899177\nIteration 60, loss = 0.00704298\nIteration 61, loss = 0.00497770\nIteration 62, loss = 0.00644555\nIteration 63, loss = 0.00422336\nIteration 64, loss = 0.00354746\nIteration 65, loss = 0.00387357\nIteration 66, loss = 0.00401059\nIteration 67, loss = 0.00356447\nIteration 68, loss = 0.00322460\nIteration 69, loss = 0.00374980\nIteration 70, loss = 0.00326441\nIteration 71, loss = 0.00321602\nIteration 72, loss = 0.00334741\nIteration 73, loss = 0.00354014\nIteration 74, loss = 0.00629154\nIteration 75, loss = 0.00661430\nIteration 76, loss = 0.00621599\nIteration 77, loss = 0.00391237\nIteration 78, loss = 0.00690556\nIteration 79, loss = 0.00574434\nTraining loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\nTraining accuracy: 0.9996771068776235\nValidation accuracy: 0.8789346246973365\n40-unit network:\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Iteration 1, loss = 0.37631294\nIteration 2, loss = 0.27670785\nIteration 3, loss = 0.25069618\nIteration 4, loss = 0.23501113\nIteration 5, loss = 0.22176468\nIteration 6, loss = 0.21070250\nIteration 7, loss = 0.19933209\nIteration 8, loss = 0.18843077\nIteration 9, loss = 0.17675223\nIteration 10, loss = 0.16661278\nIteration 11, loss = 0.15574234\nIteration 12, loss = 0.14577344\nIteration 13, loss = 0.13672148\nIteration 14, loss = 0.12788980\nIteration 15, loss = 0.11977264\nIteration 16, loss = 0.11183530\nIteration 17, loss = 0.10408129\nIteration 18, loss = 0.09882054\nIteration 19, loss = 0.09309868\nIteration 20, loss = 0.08651480\nIteration 21, loss = 0.08077091\nIteration 22, loss = 0.07644392\nIteration 23, loss = 0.07087569\nIteration 24, loss = 0.06622560\nIteration 25, loss = 0.06269006\nIteration 26, loss = 0.05816704\nIteration 27, loss = 0.05506414\nIteration 28, loss = 0.05203494\nIteration 29, loss = 0.04873037\nIteration 30, loss = 0.04528483\nIteration 31, loss = 0.04252240\nIteration 32, loss = 0.04048708\nIteration 33, loss = 0.03813203\nIteration 34, loss = 0.03647118\nIteration 35, loss = 0.03362628\nIteration 36, loss = 0.03156905\nIteration 37, loss = 0.02956951\nIteration 38, loss = 0.02813418\nIteration 39, loss = 0.02677465\nIteration 40, loss = 0.02516037\nIteration 41, loss = 0.02386482\nIteration 42, loss = 0.02226665\nIteration 43, loss = 0.02084093\nIteration 44, loss = 0.01964867\nIteration 45, loss = 0.01893682\nIteration 46, loss = 0.01737472\nIteration 47, loss = 0.01689683\nIteration 48, loss = 0.01610909\nIteration 49, loss = 0.01783461\nIteration 50, loss = 0.01460895\nIteration 51, loss = 0.01332243\nIteration 52, loss = 0.01239244\nIteration 53, loss = 0.01153411\nIteration 54, loss = 0.01105979\nIteration 55, loss = 0.01053743\nIteration 56, loss = 0.00990619\nIteration 57, loss = 0.01002111\nIteration 58, loss = 0.00855312\nIteration 59, loss = 0.00946142\nIteration 60, loss = 0.00910454\nIteration 61, loss = 0.00791385\nIteration 62, loss = 0.00767070\nIteration 63, loss = 0.00847693\nIteration 64, loss = 0.00672902\nIteration 65, loss = 0.00629873\nIteration 66, loss = 0.00645484\nIteration 67, loss = 0.00646657\nIteration 68, loss = 0.00850395\nIteration 69, loss = 0.00810044\nIteration 70, loss = 0.00811932\nIteration 71, loss = 0.00638262\nIteration 72, loss = 0.00593951\nIteration 73, loss = 0.00533894\nIteration 74, loss = 0.00499287\nIteration 75, loss = 0.00515343\nIteration 76, loss = 0.00398579\nIteration 77, loss = 0.00434683\nIteration 78, loss = 0.00531609\nIteration 79, loss = 0.00728488\nIteration 80, loss = 0.00438025\nIteration 81, loss = 0.00443063\nIteration 82, loss = 0.00357522\nIteration 83, loss = 0.00305260\nIteration 84, loss = 0.00316513\nIteration 85, loss = 0.00338865\nIteration 86, loss = 0.00503069\nIteration 87, loss = 0.00389007\nIteration 88, loss = 0.00345648\nIteration 89, loss = 0.00318632\nIteration 90, loss = 0.00331323\nIteration 91, loss = 0.00304922\nIteration 92, loss = 0.00297034\nIteration 93, loss = 0.00644098\nIteration 94, loss = 0.02121684\nTraining loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\nTraining accuracy: 0.9923043805833602\nValidation accuracy: 0.8669895076674737\n20-unit network:\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Iteration 1, loss = 0.65423207\nIteration 2, loss = 0.34671278\nIteration 3, loss = 0.29129340\nIteration 4, loss = 0.26584909\nIteration 5, loss = 0.24997232\nIteration 6, loss = 0.23907695\nIteration 7, loss = 0.23079262\nIteration 8, loss = 0.22356778\nIteration 9, loss = 0.21744450\nIteration 10, loss = 0.21146149\nIteration 11, loss = 0.20560899\nIteration 12, loss = 0.20038191\nIteration 13, loss = 0.19466724\nIteration 14, loss = 0.18971259\nIteration 15, loss = 0.18447994\nIteration 16, loss = 0.18000950\nIteration 17, loss = 0.17433077\nIteration 18, loss = 0.16904665\nIteration 19, loss = 0.16440944\nIteration 20, loss = 0.16018349\nIteration 21, loss = 0.15590088\nIteration 22, loss = 0.15012856\nIteration 23, loss = 0.14618453\nIteration 24, loss = 0.14133472\nIteration 25, loss = 0.13680620\nIteration 26, loss = 0.13328819\nIteration 27, loss = 0.12844420\nIteration 28, loss = 0.12476082\nIteration 29, loss = 0.12115142\nIteration 30, loss = 0.11809226\nIteration 31, loss = 0.11365508\nIteration 32, loss = 0.11041726\nIteration 33, loss = 0.10712768\nIteration 34, loss = 0.10362079\nIteration 35, loss = 0.10122281\nIteration 36, loss = 0.09817056\nIteration 37, loss = 0.09574029\nIteration 38, loss = 0.09292590\nIteration 39, loss = 0.09039036\nIteration 40, loss = 0.08769651\nIteration 41, loss = 0.08554696\nIteration 42, loss = 0.08280852\nIteration 43, loss = 0.08136161\nIteration 44, loss = 0.07922781\nIteration 45, loss = 0.07665097\nIteration 46, loss = 0.07448482\nIteration 47, loss = 0.07295650\nIteration 48, loss = 0.07171987\nIteration 49, loss = 0.06967534\nIteration 50, loss = 0.06826019\nIteration 51, loss = 0.06640846\nIteration 52, loss = 0.06532741\nIteration 53, loss = 0.06341559\nIteration 54, loss = 0.06126419\nIteration 55, loss = 0.06098799\nIteration 56, loss = 0.05858034\nIteration 57, loss = 0.05753939\nIteration 58, loss = 0.05679289\nIteration 59, loss = 0.05546925\nIteration 60, loss = 0.05369244\nIteration 61, loss = 0.05223620\nIteration 62, loss = 0.05154061\nIteration 63, loss = 0.05041405\nIteration 64, loss = 0.04947869\nIteration 65, loss = 0.04841466\nIteration 66, loss = 0.04784808\nIteration 67, loss = 0.04690213\nIteration 68, loss = 0.04510358\nIteration 69, loss = 0.04466452\nIteration 70, loss = 0.04327865\nIteration 71, loss = 0.04199999\nIteration 72, loss = 0.04128366\nIteration 73, loss = 0.04079477\nIteration 74, loss = 0.03963344\nIteration 75, loss = 0.03907833\nIteration 76, loss = 0.03812851\nIteration 77, loss = 0.03731989\nIteration 78, loss = 0.03635441\nIteration 79, loss = 0.03601185\nIteration 80, loss = 0.03498993\nIteration 81, loss = 0.03519475\nIteration 82, loss = 0.03386994\nIteration 83, loss = 0.03299395\nIteration 84, loss = 0.03219309\nIteration 85, loss = 0.03152654\nIteration 86, loss = 0.03059853\nIteration 87, loss = 0.03085858\nIteration 88, loss = 0.03005536\nIteration 89, loss = 0.02853245\nIteration 90, loss = 0.02914330\nIteration 91, loss = 0.02761192\nIteration 92, loss = 0.02746373\nIteration 93, loss = 0.02717920\nIteration 94, loss = 0.02667792\nIteration 95, loss = 0.02554246\nIteration 96, loss = 0.02478807\nIteration 97, loss = 0.02431518\nIteration 98, loss = 0.02413174\nIteration 99, loss = 0.02373048\nIteration 100, loss = 0.02440447\nIteration 101, loss = 0.02336744\nIteration 102, loss = 0.02225450\nIteration 103, loss = 0.02190692\nIteration 104, loss = 0.02172047\nIteration 105, loss = 0.02258792\nIteration 106, loss = 0.02076552\nIteration 107, loss = 0.02007170\nIteration 108, loss = 0.02009018\nIteration 109, loss = 0.01994816\nIteration 110, loss = 0.02013803\nIteration 111, loss = 0.01829690\nIteration 112, loss = 0.01829868\nIteration 113, loss = 0.01789614\nIteration 114, loss = 0.01781715\nIteration 115, loss = 0.01717801\nIteration 116, loss = 0.01628172\nIteration 117, loss = 0.01649335\nIteration 118, loss = 0.01589627\nIteration 119, loss = 0.01572065\nIteration 120, loss = 0.01565160\nIteration 121, loss = 0.01445764\nIteration 122, loss = 0.01458631\nIteration 123, loss = 0.01471924\nIteration 124, loss = 0.01411187\nIteration 125, loss = 0.01488691\nIteration 126, loss = 0.01499750\nIteration 127, loss = 0.01656935\nIteration 128, loss = 0.01364717\nIteration 129, loss = 0.01330677\nIteration 130, loss = 0.01360345\nIteration 131, loss = 0.01249007\nIteration 132, loss = 0.01191979\nIteration 133, loss = 0.01113554\nIteration 134, loss = 0.01076111\nIteration 135, loss = 0.01117288\nIteration 136, loss = 0.01088375\nIteration 137, loss = 0.01081474\nIteration 138, loss = 0.01136610\nIteration 139, loss = 0.01101740\nIteration 140, loss = 0.01027654\nIteration 141, loss = 0.01011141\nIteration 142, loss = 0.00974027\nIteration 143, loss = 0.00881198\nIteration 144, loss = 0.00918374\nIteration 145, loss = 0.00950146\nIteration 146, loss = 0.00893997\nIteration 147, loss = 0.00927230\nIteration 148, loss = 0.00854539\nIteration 149, loss = 0.00912607\nIteration 150, loss = 0.00917383\nIteration 151, loss = 0.00849462\nIteration 152, loss = 0.00804832\nIteration 153, loss = 0.00893414\nIteration 154, loss = 0.00770727\nIteration 155, loss = 0.00929354\nIteration 156, loss = 0.00927968\nIteration 157, loss = 0.00751206\nIteration 158, loss = 0.00841545\nIteration 159, loss = 0.00698880\nIteration 160, loss = 0.00758957\nIteration 161, loss = 0.00708127\nIteration 162, loss = 0.00833615\nIteration 163, loss = 0.00848127\nIteration 164, loss = 0.00829854\nIteration 165, loss = 0.00669969\nIteration 166, loss = 0.00600389\nIteration 167, loss = 0.00632532\nIteration 168, loss = 0.00560836\nIteration 169, loss = 0.00552574\nIteration 170, loss = 0.00503744\nIteration 171, loss = 0.00474950\nIteration 172, loss = 0.00659419\nIteration 173, loss = 0.00790138\nIteration 174, loss = 0.00629110\nIteration 175, loss = 0.00584463\nIteration 176, loss = 0.00579193\nIteration 177, loss = 0.00472679\nIteration 178, loss = 0.00441045\nIteration 179, loss = 0.00448596\nIteration 180, loss = 0.00492096\nIteration 181, loss = 0.00514689\nIteration 182, loss = 0.00792121\nIteration 183, loss = 0.00917487\nIteration 184, loss = 0.01083542\nIteration 185, loss = 0.01081117\nIteration 186, loss = 0.00840770\nIteration 187, loss = 0.00579063\nIteration 188, loss = 0.00423531\nIteration 189, loss = 0.00385730\nIteration 190, loss = 0.00404896\nIteration 191, loss = 0.00402171\nIteration 192, loss = 0.00341135\nIteration 193, loss = 0.00366555\nIteration 194, loss = 0.00399097\nIteration 195, loss = 0.00355298\nIteration 196, loss = 0.00390864\nIteration 197, loss = 0.00486513\nIteration 198, loss = 0.00432274\nIteration 199, loss = 0.00471670\nIteration 200, loss = 0.00562210\nTraining accuracy: 0.9995694758368313\nValidation accuracy: 0.8561743341404359\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2f5cadb387c780e321f0710dc3b0ed6d1f4bccaf"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}